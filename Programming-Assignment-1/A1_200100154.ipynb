{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 : Function to generate a data matrix X.\n",
        "## Inputs : Number of samples, feature dimension\n",
        "## Output : Data matrix, X\n"
      ],
      "metadata": {
        "id": "4DvWGjT0PDcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def generateDataMatrix(numberOfSamples, featureDimension):\n",
        "  # numberOfSamples would correspond to number of rows\n",
        "  # featureDimension would correspond to number of columns\n",
        "  return np.random.randn(numberOfSamples,featureDimension)"
      ],
      "metadata": {
        "id": "uuM-RESjPUb7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "numSamples = 8\n",
        "numVariables = 5\n",
        "x = generateDataMatrix(numSamples, numVariables)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQgC8X1ssMha",
        "outputId": "087d2f66-cb0c-47ed-83c0-6335ad70c2d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.2759888  -0.52551641  0.68608569  1.30651399 -0.05345351]\n",
            " [-1.36118153  2.14180252 -1.22366885 -1.03003128 -0.85115619]\n",
            " [-0.70802296 -0.4144219   0.72188903 -0.9436177   0.37795052]\n",
            " [-0.53830479  0.17244447  0.13084297  1.05140359 -1.14829787]\n",
            " [ 0.05566284 -1.30351029 -1.01765896  0.47741051  1.52842196]\n",
            " [-1.04374805  0.88330752  0.04894983 -0.58814736 -0.76620077]\n",
            " [-2.05636187 -0.19857374  0.28114242 -0.64315982 -1.20731906]\n",
            " [ 0.98269565  0.21194887  2.00602235 -0.86187977  1.33296893]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 : Function to generate the dependent variable column 't' i.e. the target vector\n",
        "\n",
        "## Inputs : Data matrix X, weight vector for each column, bias $w_{0}$, noise variance\n",
        "\n",
        "## Output : Target vector t\n"
      ],
      "metadata": {
        "id": "ct8klEirQjQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateTargetVector(dataMatrix, weights, bias, noise_variance):\n",
        "  return (dataMatrix).dot(weights.T) + bias + np.sqrt(noise_variance)*np.random.randn(np.shape(dataMatrix)[0], 1) # (std_dev)^2 = variance"
      ],
      "metadata": {
        "id": "6IYru_Q2Q-wF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "# Using the same dataMatrix that I have generated in the Unit Testing Block for Task-1\n",
        "weights = np.random.rand(1,np.shape(x)[1])\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "\n",
        "t = generateTargetVector(x, weights, bias, noise_variance)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9UeOJ93a_Kd",
        "outputId": "2085ceb1-37c8-471c-83c0-e215ccbe4035"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.14536795]\n",
            " [-1.4547137 ]\n",
            " [ 1.39342065]\n",
            " [ 0.53947491]\n",
            " [ 0.97860867]\n",
            " [-0.64650762]\n",
            " [-0.6591754 ]\n",
            " [ 4.92470312]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3 : Function to compute a linear regression estimate \n",
        "\n",
        "## Inputs : data matrix X, weight vector w\n",
        "## Output : y"
      ],
      "metadata": {
        "id": "F4Hs7jYvTxy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeLRestimate(dataMatrix, weights): # I am assuming that the weight vector includes the bias term i.e. w_0 \n",
        "  X = np.c_[np.ones(np.shape(dataMatrix)[0]), dataMatrix] # Appending a column of ones from the left to the dataMatrix\n",
        "  return (X).dot(weights.T)"
      ],
      "metadata": {
        "id": "Omq_-L8sUL28"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "# Using the same dataMatrix that I have generated in the Unit Testing Block for Task-1\n",
        "weights = np.random.rand(1, np.shape(x)[1]+1)\n",
        "y = computeLRestimate(x, weights)\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9kaabQ76nqV",
        "outputId": "3d643ad8-cd7e-426e-9dfe-9309f52b24b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.05107585]\n",
            " [-0.37072717]\n",
            " [-0.82770543]\n",
            " [ 0.0411043 ]\n",
            " [ 1.01628562]\n",
            " [-0.71430025]\n",
            " [-2.89263655]\n",
            " [ 2.07645225]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4 : Function to compute the Mean Square Error (MSE) of two vectors, y and t\n",
        "\n",
        "## Inputs : y, t\n",
        "## Outputs : MSE of y and t\n"
      ],
      "metadata": {
        "id": "1dd2GNDgUn0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeMSE(y, t):\n",
        "  N = np.shape(y-t)[0] # number of samples\n",
        "  return np.sum(np.square(y-t)) / N"
      ],
      "metadata": {
        "id": "6vJAZImcUwjQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "# t and y have been previously generated in the Unit Testing Blocks for Task-2 and Task-3 respectively\n",
        "print(computeMSE(y, t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r_QzIAd7Z6L",
        "outputId": "ac31f506-eeb9-484b-d5d7-8339d89fe149"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.535500621500451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5 : Function to estimate the weights of linear regression using pseudo-inverse, assuming L2 regularization\n",
        "\n",
        "## Inputs : X, t, and lambda\n",
        "## Outputs : w, MSE and y"
      ],
      "metadata": {
        "id": "GNQbXY2sUxZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming that phi(x) = X\n",
        "def estimateWeights(X, t, Lambda):\n",
        "  dim = np.shape(X)[1] + 1 # dimension = shape of the weight vector including the bias term = NumVariables + 1\n",
        "  X_modified = np.c_[np.ones(np.shape(X)[0]), X] # Appended a column of ones from the left to X\n",
        "  w = np.linalg.pinv(Lambda*np.identity(dim) + (X_modified.T).dot(X_modified)).dot((X_modified.T).dot(t)) \n",
        "  y = computeLRestimate(X, w.T)\n",
        "  MSE = computeMSE(y, t)\n",
        "  return w.T, MSE, y"
      ],
      "metadata": {
        "id": "8IfqlyTdi55M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "Lambda = 0.5 # random value taken for lambda2\n",
        "# x and t have been previously generated in the Unit Testing Blocks for Task-1 and Task-2 respectively\n",
        "w, MSE, y = estimateWeights(x, t, Lambda)\n",
        "print(\"Weights : \", w)\n",
        "print(\"MSE : \", MSE)\n",
        "print(\"y : \", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDk9W4137ue4",
        "outputId": "572fa8ac-c03a-4d46-ce2f-2a8ce197ca28"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights :  [[0.6749543  0.18558195 0.16800511 1.12466527 0.10927972 0.95469127]]\n",
            "MSE :  0.19712913122878745\n",
            "y :  [[ 1.68682598]\n",
            " [-1.51919342]\n",
            " [ 1.54352433]\n",
            " [-0.23019211]\n",
            " [ 0.83310464]\n",
            " [-0.11105191]\n",
            " [-0.64674092]\n",
            " [ 4.32742485]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 6 : Function to compute the gradient of MSE with respect to its weight vector\n",
        "\n",
        "## Inputs : X matrix, t vector, and w vector\n",
        "## Outputs : gradient vector"
      ],
      "metadata": {
        "id": "mP7sidjoub_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You should include the bias term in this task\n",
        "def computeMSEgradient(X, t, weights):\n",
        "  N = np.shape(X)[0] # Number of Samples\n",
        "  MSEgradient = np.append(np.sum(2*(computeLRestimate(X, weights)-t))/N, 2*(X.T).dot(computeLRestimate(X, weights)-t)/N) # Appending the gradient of MSE wrt to the bias term to the gradient vector of MSE wrt to the weights vector\n",
        "  return MSEgradient.T"
      ],
      "metadata": {
        "id": "6L60PuD4udb9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "# Randomly generating the weight vector\n",
        "weights = np.random.randn(1, 1 + np.shape(x)[1])\n",
        "# x and t have been previously generated in the Unit Testing Blocks for Task-1 and Task-2 respectively\n",
        "print(computeMSEgradient(x, t, weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP6PfrRd-kAR",
        "outputId": "cefe826c-13d5-46e8-ca2a-5049af34f4ef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.53052493 -3.76069902  2.14356546 -2.08546484  0.84961049 -5.37869804]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 7 : Function to compute L2 norm of a vector w passed as a numpy array. Exclude bias w0.\n",
        "\n",
        "## Inputs : w\n",
        "## Outputs : L2 norm of the vector "
      ],
      "metadata": {
        "id": "phb351dczX3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L2norm(weights):\n",
        "  w = np.copy(weights) # deep copy\n",
        "  w[0][0] = 0 # since we are asked to exclude the bias term i.e. w_0\n",
        "  return np.sqrt(np.sum(np.square(w)))\n",
        "  # Note : this could have been implemented using np.linalg.norm(weights)"
      ],
      "metadata": {
        "id": "B8HgXAC6zZAe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "w = np.array([[1.07425434, 0.88373724, 1.68189801, 2.84855541, 3.48447525]])\n",
        "print(L2norm(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scfi8O0VTDds",
        "outputId": "45df7fa3-2f3c-4f16-a2ef-f884e312922e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.8852439158252485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 8 : Function to compute the gradient of L2 norm with respect to weight vector \n",
        "\n",
        "## Inputs : w vector\n",
        "## Outputs : gradient vector, where the gradient wrt the bias term is 0"
      ],
      "metadata": {
        "id": "Wa4s6_WYzcXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude the bias term in this task\n",
        "def computeL2gradient(weights):\n",
        "  w = np.copy(weights) # deep copy\n",
        "  ans = 2*w\n",
        "  ans[0][0] = 0 # since the gradient wrt the bias term is 0\n",
        "  return ans"
      ],
      "metadata": {
        "id": "suJUuIvUzfY0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "w = np.array([[1.07425434, 0.88373724, 1.68189801, 2.84855541, 3.48447525]])\n",
        "print(computeL2gradient(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2IY8vEzIynJ",
        "outputId": "4f72f260-a3b2-46ff-f85f-534bf8a3a74d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         1.76747448 3.36379602 5.69711082 6.9689505 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 9 : Function to compute L1 norm of a vector w passed as a numpy array. Exclude bias w0.\n",
        "\n",
        "## Inputs : w\n",
        "## Outputs : L1 norm of the vector "
      ],
      "metadata": {
        "id": "xOr250iAI8TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L1norm(weights):\n",
        "  w = np.copy(weights) # deep copy\n",
        "  w[0][0] = 0 # since we are asked to exclude the bias term i.e. w_0\n",
        "  return np.sum(np.absolute(w))"
      ],
      "metadata": {
        "id": "mTaLU77XJCJ-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "w = np.array([[1, 0.2, -0.2, 0.5, -0.5]])\n",
        "print(L1norm(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th6q-VgVJbw8",
        "outputId": "46aa26f3-9288-48c6-a5b8-48e0feaad37f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 10 : Function to compute the gradient of L1 norm with respect to the weight vectors\n",
        "\n",
        "## Inputs : w vector\n",
        "## Outputs : gradient vector, where gradient with respect to w0 is 0"
      ],
      "metadata": {
        "id": "OFy2rYQsJ8Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeL1gradient(weights):\n",
        "  w = np.copy(weights) # deep copy\n",
        "  ans = np.sign(w) # np.sign -> returns -1 if x < 0, 0 if x==0, 1 if x > 0\n",
        "  ans[0][0] = 0 # since the gradient wrt the bias term is 0\n",
        "  return ans"
      ],
      "metadata": {
        "id": "E1J6PNCuKeg3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "w = np.array([[1, 0.2, -0.2, 0.5, -0.5]])\n",
        "print(computeL1gradient(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOr2wpDKLqL0",
        "outputId": "91575700-dc43-4089-8558-5d0959468b05"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  1. -1.  1. -1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 11 : Function for a single update of weights of linear regression using gradient descent\n",
        "\n",
        "## Inputs : X, t, w, eta, lambda2, lambda1 \n",
        "## Outputs : Updated weights, Updated MSE"
      ],
      "metadata": {
        "id": "HkVtF7UxL_hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleWeightUpdate(X, t, weights, eta, Lambda1=0, Lambda2=0):\n",
        "  # Implementing the same update rule as given in the Book : Bishop - Pattern Recognition And Machine Learning - Springer - 2006 Edition\n",
        "  updated_weights = weights - eta*(computeMSEgradient(X, t, weights) + Lambda2*computeL2gradient(weights) + Lambda1*computeL1gradient(weights))\n",
        "  updated_y = computeLRestimate(X, updated_weights)\n",
        "  updated_mse = computeMSE(updated_y, t)\n",
        "  return updated_weights, updated_mse"
      ],
      "metadata": {
        "id": "-Py0ry3xMh96"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "weights = np.random.rand(1, 1 + np.shape(x)[1])\n",
        "print(\"Weights : \", weights)\n",
        "print(\"MSE : \", computeMSE(computeLRestimate(x, weights), t))\n",
        "updated_weights, updated_mse = singleWeightUpdate(x, t, weights, 0.01, 0, 0)\n",
        "print(\"Updated Weights : \", updated_weights)\n",
        "print(\"Updated MSE : \", updated_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PtYrp_5RZvG",
        "outputId": "0e14ab29-9c20-41a5-95b4-51b8e11271ef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights :  [[0.10678827 0.16187086 0.27610982 0.1300903  0.3527141  0.32780396]]\n",
            "MSE :  2.837111070264461\n",
            "Updated Weights :  [[0.12211046 0.17397384 0.26703966 0.15685739 0.34641659 0.34710004]]\n",
            "Updated MSE :  2.680617443429711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimateLRweights(X, t, eta, max_iter, min_change_NRMSE, Lambda1=0, Lambda2=0):\n",
        "  iter = 0 # a counter to keep a track of the number of iterations\n",
        "  w = np.random.rand(1, 1 + np.shape(X)[1]) # randomly initializing the initial weight vector including the bias term\n",
        "  old_mse = computeMSE(computeLRestimate(X, w), t)\n",
        "  old_rmse = np.sqrt(old_mse)\n",
        "  old_nrmse = old_rmse / np.sqrt(np.std(t))\n",
        "  while(iter<max_iter): # iter-Stopping criteria : max_iter has been reached\n",
        "\n",
        "    new_w, new_mse = singleWeightUpdate(X, t, w, eta, Lambda1, Lambda2)\n",
        "    new_rmse = np.sqrt(new_mse)\n",
        "    new_nrmse = new_rmse / np.sqrt(np.std(t))\n",
        "\n",
        "    if abs(new_nrmse - old_nrmse) < min_change_NRMSE:\n",
        "      break # epsilon-Stopping criteria : the normalized RMSE does not change by more than min_change_NRMSE\n",
        "    else:\n",
        "      iter += 1 # incrementing the number of iterations by 1 after every single weight update in case the epsilon-stopping criteria is not satisfied\n",
        "      w = new_w\n",
        "      old_nrmse = new_nrmse\n",
        "\n",
        "  return new_w, new_nrmse"
      ],
      "metadata": {
        "id": "AI0ekKhoS8lP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing Block\n",
        "FinalWeights, FinalNRMSE = estimateLRweights(x, t, 0.001, 1000, 0.01 , 0, 0)\n",
        "\n",
        "print(\"Final Weights : \", FinalWeights)\n",
        "print(\"Final NRMSE : \", FinalNRMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv8c9A-v_Vaw",
        "outputId": "9af5b54c-6de4-429e-ab43-271428d6e2f1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights :  [[0.32277442 0.7775416  0.10622468 0.5993509  0.89596631 0.42708616]]\n",
            "Final NRMSE :  1.120256475050676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (a) : Training and validation NRMSE obtained using pseudo inverse with number of training samples"
      ],
      "metadata": {
        "id": "BKptOZ0nOfAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the same weights and noise variance, but vary the number of training samples. But first, for each number of training samples, try new random seeds (say 11 to 21) to generate the training data. Have a good number of validation samples. What you are looking for is the mean and variance (spread) of NMRSE.\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension)\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(100, featureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(200, featureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(300, featureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(400, featureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(500, featureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(600, featureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(700, featureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(800, featureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(900, featureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(1000, featureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:80,], x1[-20:,]\n",
        "t1 = generateTargetVector(training_data1, weights, bias, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, weights, bias, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:160,], x2[-40:,]\n",
        "t2 = generateTargetVector(training_data2, weights, bias, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, weights, bias, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:240,], x3[-60:,]\n",
        "t3 = generateTargetVector(training_data3, weights, bias, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, weights, bias, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:320,], x4[-80:,]\n",
        "t4 = generateTargetVector(training_data4, weights, bias, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, weights, bias, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:400,], x5[-100:,]\n",
        "t5 = generateTargetVector(training_data5, weights, bias, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, weights, bias, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:480,], x6[-120:,]\n",
        "t6 = generateTargetVector(training_data6, weights, bias, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, weights, bias, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:560,], x7[-140:,]\n",
        "t7 = generateTargetVector(training_data7, weights, bias, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, weights, bias, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:640,], x8[-160:,]\n",
        "t8 = generateTargetVector(training_data8, weights, bias, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, weights, bias, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:720,], x9[-180:,]\n",
        "t9 = generateTargetVector(training_data9, weights, bias, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, weights, bias, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, weights, bias, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, weights, bias, noise_variance)\n",
        "\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(training_data1, t1, Lambda)\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(training_data2, t2, Lambda)\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(training_data3, t3, Lambda)\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(training_data4, t4, Lambda)\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(training_data5, t5, Lambda)\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(training_data6, t6, Lambda)\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(training_data7, t7, Lambda)\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(training_data8, t8, Lambda)\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(training_data9, t9, Lambda)\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(training_data10, t10, Lambda)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "mse_t = np.array([mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6, mse_t7, mse_t8, mse_t9, mse_t10])\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "\n",
        "nrmse_t = nrmse(mse_t, noise_variance)\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yM--HePPOeXo",
        "outputId": "3cd00ffc-f3c5-4339-8111-61f7ec0865fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2283f53c40>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   Spread of Validation_NRMSE > Spread of Training_NRMSE\n",
        "2.   Mean of Validation_NRMSE > Mean of Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "The validation_NRMSE error is generally higher than Training_NRMSE because the error is computed on an unknown dataset that the model hasn't seen.\n"
      ],
      "metadata": {
        "id": "cBVMZE1s1vm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (b) : Training and validation NRMSE obtained using pseudo inverse with number of variables"
      ],
      "metadata": {
        "id": "OivKyfmCPlKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, 5)\n",
        "w1 = np.random.rand(1, 5)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, 7)\n",
        "w2 = np.random.rand(1, 7)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, 9)\n",
        "w3 = np.random.rand(1, 9)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, 11)\n",
        "w4 = np.random.rand(1, 11)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, 13)\n",
        "w5 = np.random.rand(1, 13)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, 15)\n",
        "w6 = np.random.rand(1, 15)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, 17)\n",
        "w7 = np.random.rand(1, 17)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, 19)\n",
        "w8 = np.random.rand(1, 19)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, 21)\n",
        "w9 = np.random.rand(1, 21)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, 23)\n",
        "w10 = np.random.rand(1, 23)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, w1, bias, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, w1, bias, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, w2, bias, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, w2, bias, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, w3, bias, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, w3, bias, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, w4, bias, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, w4, bias, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, w5, bias, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, w5, bias, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, w6, bias, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, w6, bias, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, w7, bias, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, w7, bias, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, w8, bias, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, w8, bias, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, w9, bias, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, w9, bias, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, w10, bias, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, w10, bias, noise_variance)\n",
        "\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(training_data1, t1, Lambda)\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(training_data2, t2, Lambda)\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(training_data3, t3, Lambda)\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(training_data4, t4, Lambda)\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(training_data5, t5, Lambda)\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(training_data6, t6, Lambda)\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(training_data7, t7, Lambda)\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(training_data8, t8, Lambda)\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(training_data9, t9, Lambda)\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(training_data10, t10, Lambda)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "mse_t = np.array([mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6, mse_t7, mse_t8, mse_t9, mse_t10])\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "\n",
        "nrmse_t = nrmse(mse_t, noise_variance)\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NdZ947xcTdrR",
        "outputId": "9951c42a-b6e8-4a09-ec19-054472437c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2284145670>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   Spread of Validation_NRMSE > Spread of Training_NRMSE\n",
        "2.   Mean of Validation_NRMSE > Mean of Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "The validation_NRMSE error is generally higher than Training_NRMSE because the error is computed on an unknown dataset that the model hasn't seen."
      ],
      "metadata": {
        "id": "6oQkxUk34HjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (c) : Training and validation NRMSE obtained using pseudo inverse with noise variance"
      ],
      "metadata": {
        "id": "7QPF1LsoV61Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise_variance range -> [1, 20]\n",
        "# std_dev range -> [1, sqrt(20)]\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "FeatureDimension = 15\n",
        "w = np.random.rand(1, FeatureDimension)\n",
        "bias = 1\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, w, bias, 1)\n",
        "v1 = generateTargetVector(validation_data1, w, bias, 1)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, w, bias, 3)\n",
        "v2 = generateTargetVector(validation_data2, w, bias, 3)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, w, bias, 5)\n",
        "v3 = generateTargetVector(validation_data3, w, bias, 5)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, w, bias, 7)\n",
        "v4 = generateTargetVector(validation_data4, w, bias, 7)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, w, bias, 9)\n",
        "v5 = generateTargetVector(validation_data5, w, bias, 9)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, w, bias, 11)\n",
        "v6 = generateTargetVector(validation_data6, w, bias, 11)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, w, bias, 13)\n",
        "v7 = generateTargetVector(validation_data7, w, bias, 13)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, w, bias, 15)\n",
        "v8 = generateTargetVector(validation_data8, w, bias, 15)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, w, bias, 17)\n",
        "v9 = generateTargetVector(validation_data9, w, bias, 17)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, w, bias, 19)\n",
        "v10 = generateTargetVector(validation_data10, w, bias, 19)\n",
        "\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(training_data1, t1, Lambda)\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(training_data2, t2, Lambda)\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(training_data3, t3, Lambda)\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(training_data4, t4, Lambda)\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(training_data5, t5, Lambda)\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(training_data6, t6, Lambda)\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(training_data7, t7, Lambda)\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(training_data8, t8, Lambda)\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(training_data9, t9, Lambda)\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(training_data10, t10, Lambda)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "mse_t = np.array([mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6, mse_t7, mse_t8, mse_t9, mse_t10])\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "\n",
        "nrmse_t = nrmse(mse_t, noise_variance)\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "eEK6fqHQWPPF",
        "outputId": "90c112b5-7656-412d-bb58-f0d0ae0970e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f22814f5070>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   Validation_NRMSE in part (c) > Validation_NRMSE in part (a)\n",
        "2.   Validation_NRMSE in part (c) > Validation_NRMSE in part (b)\n",
        "3. Training_NRMSE in part (c) > Training_NRMSE in part (a)\n",
        "4.   Training_NRMSE in part (c) > Training_NRMSE in part (b)\n",
        "\n",
        "# Potential Reason :    \n",
        "The increase in Validation_NRMSE can be because of the variance of the noise present in the target vector due to which it is becoming difficult for the model to generalize over unseen data.\n",
        "\n",
        "The increase in Training_NRMSE can be because of the variance of the noise present in the target vector due to which it is becoming difficult for the model to fit over training data."
      ],
      "metadata": {
        "id": "LEu2k-vl4n0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (d) : Training and validation NRMSE obtained using pseudo inverse with w0 i.e. the bias term"
      ],
      "metadata": {
        "id": "egEH189JZFQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "FeatureDimension = 15\n",
        "w = np.random.rand(1, FeatureDimension)\n",
        "noise_variance = 0.25\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b1 = np.random.randn()\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b2 = np.random.randn()\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b3 = np.random.randn()\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b4 = np.random.randn()\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b5 = np.random.randn()\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b6 = np.random.randn()\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b7 = np.random.randn()\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b8 = np.random.randn()\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b9 = np.random.randn()\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "b10 = np.random.randn()\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, w, b1, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, w, b1, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, w, b2, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, w, b2, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, w, b3, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, w, b3, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, w, b4, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, w, b4, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, w, b5, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, w, b6, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, w, b6, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, w, b6, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, w, b7, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, w, b7, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, w, b8, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, w, b8, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, w, b9, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, w, b9, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, w, b10, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, w, b10, noise_variance)\n",
        "\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(training_data1, t1, Lambda)\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(training_data2, t2, Lambda)\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(training_data3, t3, Lambda)\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(training_data4, t4, Lambda)\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(training_data5, t5, Lambda)\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(training_data6, t6, Lambda)\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(training_data7, t7, Lambda)\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(training_data8, t8, Lambda)\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(training_data9, t9, Lambda)\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(training_data10, t10, Lambda)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "mse_t = np.array([mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6, mse_t7, mse_t8, mse_t9, mse_t10])\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "\n",
        "nrmse_t = nrmse(mse_t, noise_variance)\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1NQqO7xRZEOC",
        "outputId": "eab44d50-b2f7-4d1d-c03b-77e90e5d9587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb1b822220>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMhklEQVR4nO3db4hdd53H8c8nM22Z2pXFO0NdJk2jTLAUVqUM6oOFdiGBWx9s1/XBGpbNoJUgrElABN1FLCi6CD5pBndLkJDJk4gPdqFl3ZHE3SUPrNCJuk1KrXvppu2MfzLeorYmtr2Trw/mjk5rZu6dzrnzu/d73y8o5M45zPmSXt78cu459zgiBAAYfLtKDwAAqAZBB4AkCDoAJEHQASAJgg4ASYyWOvD4+Hjs3bu31OEBYCBduHDhFxExcaNtxYK+d+9eLSwslDo8AAwk289ttI1TLgCQBEEHgCQIOgAkQdABIAmCDqBnms2mjh49qmazWXqUoUDQAfTM3NycLl68qNOnT5ceZSgQdAA90Ww2NT8/r4jQ/Pw8q/QdQNAB9MTc3JyuX78uSVpZWWGVvgMIOoCeOHfunFqtliSp1Wrp7NmzhSfKj6AD6In9+/drdHT1ZvTR0VEdOHCg8ET5EXQAPTEzM6Ndu1YTMzIyokOHDhWeKD+CDqAnarWa6vW6bKter6tWq5UeKb1iX84FIL+ZmRldvnyZ1fkOIegAeqZWq+n48eOlxxganHIBgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIomPQbZ+0fcX2pQ22P2D7Sds/tL1g+y+qHxMA0Ek3K/RTkuqbbP+OpPdExHslfUzS1yuYCwCwRR2DHhHnJb24yfaXIyLaL98iKTbaFwDQO5WcQ7f9Ids/kvQfWl2lb7Tf4fZpmYXl5eUqDg0AaKsk6BHx7xFxl6S/lvTFTfY7ERHTETE9MTFRxaEBAG2VXuXSPj3zTtvjVf5eAEBn2w667Snbbv/5Hkm3SGpu9/cCALam40OibZ+RdJ+kcduLkh6SdJMkRcQjkj4s6ZDt1yRdk/S36z4kBQDskI5Bj4iDHbZ/RdJXKpsIAPCmcKcoACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASXQMuu2Ttq/YvrTB9r+z/aTti7a/a/s91Y8JAOikmxX6KUn1Tbb/v6R7I+LPJX1R0okK5gIAbNFopx0i4rztvZts/+66l9+TtHv7YwEAtqrqc+gPSvrPjTbaPmx7wfbC8vJyxYcGgOFWWdBt/6VWg/6ZjfaJiBMRMR0R0xMTE1UdGgCgLk65dMP2uyV9XdL9EdGs4ncCALZm2yt023sk/Zukv4+IH29/JADAm9FxhW77jKT7JI3bXpT0kKSbJCkiHpH0eUk1Sf9iW5JaETHdq4EBADfWzVUuBzts/7ikj1c2EQDgTeFOUQBIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEh2Dbvuk7Su2L22w/S7bj9t+xfanqx8RANCNblbopyTVN9n+oqSjkr5axUDYumazqaNHj6rZbJYeBUBBHYMeEee1Gu2Ntl+JiCckvVblYOje3NycLl68qNOnT5ceBUBBnEMfcM1mU/Pz84oIzc/Ps0oHhtiOBt32YdsLtheWl5d38tBpzc3N6fr165KklZUVVunAENvRoEfEiYiYjojpiYmJnTx0WufOnVOr1ZIktVotnT17tvBEAErhlMuA279/v0ZHRyVJo6OjOnDgQOGJAJTSzWWLZyQ9LuldthdtP2j7E7Y/0d7+dtuLkj4l6XPtfd7a27GxZmZmRrt2rf5vHBkZ0aFDhwpPBKCU0U47RMTBDtt/Jml3ZRNhS2q1mur1uh577DHV63XVarXSIwEopGPQ0f9mZmZ0+fJlVufAkCPoCdRqNR0/frz0GAAK40NRAEiCoANAEgQdAJLgHDqQ1OzsrBqNRtEZlpaWJEmTk5NF55CkqakpHTlypPQYPUXQAfTMtWvXSo8wVAg6kFQ/rEaPHTsmSXr44YcLTzIcOIcOAEkQdABIgqADQBKcQwcq1g9Xl/SLtb+HtXPpw67XV9oQdKBijUZD//fUD7TntpXSoxR382urJwFeeW6h8CTlPf/ySM+PQdCBHthz24r+6Z5flx4DfeTL3+/9t4pzDh0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkAS3/m9Dv3wJU7885msYHvEF9DOCngCP+QIgEfRt6ZfVKI/5AiBxDh0A0iDoAJAEQQeAJAg6ACQxsB+K9sslg/2A5za+XunLJ5eWlvSbl0Z25Ak1GBzPvTSit7QvMe6VgQ16o9HQDy89rZVb31Z6lOJ2vRqSpAvP/rzwJOWNXH2x9AhAMQMbdElaufVtunbXB0uPgT4y9qNvlR5Bk5OTeqX1U54pitf58vffqlt6fPMf59ABIImOQbd90vYV25c22G7bx203bD9p+57qxwQAdNLNCv2UpPom2++XtK/932FJ/7r9sQAAW9Ux6BFxXtJmnzQ9IOl0rPqepD+1/WdVDQgA6E4V59AnJb2w7vVi+2d/xPZh2wu2F5aXlys4NABgzY5+KBoRJyJiOiKmJyYmdvLQAJBeFUFfknTHute72z8DAOygKoL+qKRD7atdPiDpVxHx0wp+LwBgCzreWGT7jKT7JI3bXpT0kKSbJCkiHpH0LUkflNSQdFXSR3s1LDAonn+ZW/8l6edXV9eMt996vfAk5T3/8oj29fgYHYMeEQc7bA9J/1DZRMCAm5qaKj1C33i1/T1Dt9zJ38k+9f69MdC3/gP9qF+eZNUPeJrWzuLWfwBIgqADQBIEHQCSIOgAkMTAfii6tLSkkau/6ovvv0b/GLna1NJSq/QYQBGs0AEgiYEN+uTkpCSXHqMv7Prtr7XrtzwdZ5Xb7w1g+AzsKRdu3viDRuMlSdLUO28vPEk/uJ33BobWwAadmzf+gJs3AEgDfMoFAPB6A7tC7wezs7NqtL+roqS1GdZW6qVMTU3xLyegIIKewNjYWOkRAPQBgr4NrEYB9BPOoQNAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJNFV0G3XbT9ju2H7szfYfqft79h+0vb/2N5d/agAgM10DLrtEUlfk3S/pLslHbR99xt2+6qk0xHxbklfkPTPVQ8KANhcNyv090lqRMSzEfGqpG9IeuAN+9wt6b/af/7vG2wHAPTYaBf7TEp6Yd3rRUnvf8M+/yvpbyQ9LOlDkv7Edi0imut3sn1Y0mFJ2rNnz5udGUAXZmdn1Wg0is6wdvxjx44VnUOSpqamdOTIkdJj9FRVH4p+WtK9tn8g6V5JS5JW3rhTRJyIiOmImJ6YmKjo0AD61djYmMbGxkqPMTS6WaEvSbpj3evd7Z/9XkT8RKsrdNm+TdKHI+KXVQ0JYOuyr0bxx7pZoT8haZ/td9i+WdJHJD26fgfb47bXftc/SjpZ7ZgAgE46Bj0iWpI+Kenbkp6W9M2IeMr2F2z/VXu3+yQ9Y/vHkm6X9KUezQsA2IAjosiBp6enY2FhocixAWBQ2b4QEdM32sadogCQBEEHgCQIOgAkQdABIAmCDgBJFLvKxfaypOeKHDyncUm/KD0EcAO8N6t1Z0Tc8Fb7YkFHtWwvbHQpE1AS782dwykXAEiCoANAEgQ9jxOlBwA2wHtzh3AOHQCSYIUOAEkQdABIgqAPONt128/Ybtj+bOl5gDW2T9q+YvtS6VmGBUEfYLZHJH1N0v1afVD3Qdt3l50K+L1TkuqlhxgmBH2wvU9SIyKejYhXJX1D0gOFZwIkSRFxXtKLpecYJgR9sE1KemHd68X2zwAMIYIOAEkQ9MG2JOmOda93t38GYAgR9MH2hKR9tt9h+2ZJH5H0aOGZABRC0AdYRLQkfVLStyU9LembEfFU2amAVbbPSHpc0rtsL9p+sPRM2XHrPwAkwQodAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASOJ3s6DGEaJWn/kAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   We can notice 1 outlier each for both the classes i.e. (Training_NRMSE and Validation_NRMSE)\n",
        "2.   Spread for Validation_NRMSE > Spread for Training_NRMSE\n",
        "3. Upon comparing with the Validation_NRMSE obtained for (a) and (b), the Validation_NRMSE obtained in this case is closer to 0.\n",
        "\n",
        "# Potential Reason :    \n",
        "The introduction of the bias term allows us to shift the hyperplane in an attempt to better fit the data without the risk of overfitting "
      ],
      "metadata": {
        "id": "u9WsHaEz6ui6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (e) : Training and validation NRMSE obtained using pseudo inverse with lambda2"
      ],
      "metadata": {
        "id": "jRuopjQVbIpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "FeatureDimension = 15\n",
        "w = np.random.rand(1, FeatureDimension)\n",
        "noise_variance = 0.25\n",
        "bias = 1\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, w, bias, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, w, bias, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, w, bias, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, w, bias, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, w, bias, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, w, bias, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, w, bias, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, w, bias, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, w, bias, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, w, bias, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, w, bias, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, w, bias, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, w, bias, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, w, bias, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, w, bias, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, w, bias, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, w, bias, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, w, bias, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, w, bias, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, w, bias, noise_variance)\n",
        "\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(training_data1, t1, 0.1)\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(training_data2, t2, 0.2)\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(training_data3, t3, 0.3)\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(training_data4, t4, 0.4)\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(training_data5, t5, 0.5)\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(training_data6, t6, 0.6)\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(training_data7, t7, 0.7)\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(training_data8, t8, 0.8)\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(training_data9, t9, 0.9)\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(training_data10, t10, 1)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "mse_t = np.array([mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6, mse_t7, mse_t8, mse_t9, mse_t10])\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "\n",
        "nrmse_t = nrmse(mse_t, noise_variance)\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BnzbxJbybRTG",
        "outputId": "d88b015a-07c8-4565-faa4-f0f4ae5da448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb1bc6f100>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   We can notice 3 outliers for class-1 i.e. (Validation_NRMSE)\n",
        "2.   Spread for Validation_NRMSE < Spread for Training_NRMSE\n",
        "3. Upon comparing with the Validation_NRMSE obtained for (a) and (b), the Validation_NRMSE obtained in this case is further away from 0.\n",
        "\n",
        "# Potential Reason :    \n",
        "The introduction of the regularization term makes sure that our model is not overfitting to the training data. This allows it to generalize better on unseen data. In this way, the L2 regularization deals with independent variables that are highly correlated by constricting the coefficient and keeping all the variables. \n"
      ],
      "metadata": {
        "id": "xfadc-lS8RkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (f) : Time taken to solve pseudo inverse with number of samples and number of variables and its breaking points\n"
      ],
      "metadata": {
        "id": "FuZR5Sm8arYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different number of samples in powers of 10\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension)\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(10)\n",
        "x1 = generateDataMatrix(10, featureDimension)\n",
        "t1 = generateTargetVector(x1, weights, bias, noise_variance)\n",
        "\n",
        "x2 = generateDataMatrix(100, featureDimension)\n",
        "t2 = generateTargetVector(x2, weights, bias, noise_variance)\n",
        "\n",
        "x3 = generateDataMatrix(1000, featureDimension)\n",
        "t3 = generateTargetVector(x3, weights, bias, noise_variance)\n",
        "\n",
        "x4 = generateDataMatrix(10000, featureDimension)\n",
        "t4 = generateTargetVector(x4, weights, bias, noise_variance)\n",
        "\n",
        "x5 = generateDataMatrix(100000, featureDimension)\n",
        "t5 = generateTargetVector(x5, weights, bias, noise_variance)\n",
        "\n",
        "x6 = generateDataMatrix(1000000, featureDimension)\n",
        "t6 = generateTargetVector(x6, weights, bias, noise_variance)\n",
        "\n",
        "x7 = generateDataMatrix(10000000, featureDimension)\n",
        "t7 = generateTargetVector(x7, weights, bias, noise_variance)\n",
        "\n",
        "\n",
        "time_samples = []\n",
        "\n",
        "start = time.time()\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(x1, t1, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(x2, t2, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(x3, t3, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(x4, t4, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(x5, t5, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(x6, t6, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(x7, t7, Lambda)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "time_samples = np.array(time_samples)\n",
        "n_samples = np.array([10, 100, 1000, 10000, 100000, 1000000, 10000000]) # Google Colab crashes when I use n_sample = 100000000\n",
        "\n",
        "plt.plot(n_samples, time_samples)\n",
        "plt.title(\"Time Taken for Pseudo Inverse v/s Number of Samples\")\n",
        "plt.xlabel(\"Number of Samples\")\n",
        "plt.ylabel(\"Time Taken for Pseudo Inverse\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "1O98H2MJazjc",
        "outputId": "bf35ada3-7a6b-489e-b879-d326cacb9296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Time Taken for Pseudo Inverse')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.  The plot between Time Taken for Pseudo Inverse v/s Number of Samples is Linear\n",
        "2. The breaking point in terms of number of samples = 100000000\n",
        "\n",
        "# Potential Reason :    \n",
        "As the number of rows increase, computing the pseudo inverse of the matrix increases linearly\n",
        "The RAM of the virtual machine Google colab had assigned me crashes when the number of rows = number of samples = 100000000\n"
      ],
      "metadata": {
        "id": "ipO2kT9m9OLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different number of variables in powers of 10\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, 10)\n",
        "w1 = np.random.rand(1, np.shape(x1)[1])\n",
        "t1 = generateTargetVector(x1, w1, bias, noise_variance)\n",
        "\n",
        "x2 = generateDataMatrix(NumberOfSamples, 100)\n",
        "w2 = np.random.rand(1, np.shape(x2)[1])\n",
        "t2 = generateTargetVector(x2, w2, bias, noise_variance)\n",
        "\n",
        "x3 = generateDataMatrix(NumberOfSamples, 500)\n",
        "w3 = np.random.rand(1, np.shape(x3)[1])\n",
        "t3 = generateTargetVector(x3, w3, bias, noise_variance)\n",
        "\n",
        "x4 = generateDataMatrix(NumberOfSamples, 1000)\n",
        "w4 = np.random.rand(1, np.shape(x4)[1])\n",
        "t4 = generateTargetVector(x4, w4, bias, noise_variance)\n",
        "\n",
        "x5 = generateDataMatrix(NumberOfSamples, 2000)\n",
        "w5 = np.random.rand(1, np.shape(x5)[1])\n",
        "t5 = generateTargetVector(x5, w5, bias, noise_variance)\n",
        "\n",
        "x6 = generateDataMatrix(NumberOfSamples, 4000)\n",
        "w6 = np.random.rand(1, np.shape(x6)[1])\n",
        "t6 = generateTargetVector(x6, w6, bias, noise_variance)\n",
        "\n",
        "x7 = generateDataMatrix(NumberOfSamples, 5000)\n",
        "w7 = np.random.rand(1, np.shape(x7)[1])\n",
        "t7 = generateTargetVector(x7, w7, bias, noise_variance)\n",
        "\n",
        "x8 = generateDataMatrix(NumberOfSamples, 7000)\n",
        "w8 = np.random.rand(1, np.shape(x8)[1])\n",
        "t8 = generateTargetVector(x8, w8, bias, noise_variance)\n",
        "\n",
        "x9 = generateDataMatrix(NumberOfSamples, 9000)\n",
        "w9 = np.random.rand(1, np.shape(x9)[1])\n",
        "t9 = generateTargetVector(x9, w9, bias, noise_variance)\n",
        "\n",
        "x10 = generateDataMatrix(NumberOfSamples, 10000)\n",
        "w10 = np.random.rand(1, np.shape(x10)[1])\n",
        "t10 = generateTargetVector(x10, w10, bias, noise_variance)\n",
        "\n",
        "time_vars = []\n",
        "\n",
        "start = time.time()\n",
        "w_t1, mse_t1, y_t1 = estimateWeights(x1, t1, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t2, mse_t2, y_t2 = estimateWeights(x2, t2, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t3, mse_t3, y_t3 = estimateWeights(x3, t3, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t4, mse_t4, y_t4 = estimateWeights(x4, t4, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t5, mse_t5, y_t5 = estimateWeights(x5, t5, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t6, mse_t6, y_t6 = estimateWeights(x6, t6, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t7, mse_t7, y_t7 = estimateWeights(x7, t7, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t8, mse_t8, y_t8 = estimateWeights(x8, t8, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t9, mse_t9, y_t9 = estimateWeights(x9, t9, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t10, mse_t10, y_t10 = estimateWeights(x10, t10, Lambda)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "time_vars = np.array(time_vars)\n",
        "n_vars = np.array([10, 100, 500, 1000, 2000, 4000, 5000, 7000, 9000, 10000]) # Google Colab crashes when I use n_vars = 100000\n",
        "\n",
        "plt.plot(n_vars, time_vars)\n",
        "plt.title(\"Time Taken for Pseudo Inverse v/s Number of Variables\")\n",
        "plt.xlabel(\"Number of Variables\")\n",
        "plt.ylabel(\"Time Taken for Pseudo Inverse\")"
      ],
      "metadata": {
        "id": "DDF35xuoUL_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "74617d20-8051-4d83-d6a5-a12b3ba1f89d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Time Taken for Pseudo Inverse')"
            ]
          },
          "metadata": {},
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.  The plot between Time Taken for Pseudo Inverse v/s Number of Variables is Exponential\n",
        "2. The breaking point in terms of number of samples = 100000\n",
        "\n",
        "# Potential Reason :    \n",
        "As the number of columns increase, computing the pseudo inverse of the matrix increases exponentially.\n",
        "The RAM of the virtual machine Google colab had assigned me crashes when the number of columns = number of variables = 100000"
      ],
      "metadata": {
        "id": "yQ5q_By3-U92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (g) : Training and validation NRMSE obtained using gradient descent with max_iter"
      ],
      "metadata": {
        "id": "lBzO4709bGCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will vary the value of max_iter from 10 to 10000000000\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension) # w is kept fixed and it includes the bias term i.e. w_0\n",
        "bias = 1\n",
        "noise_variance = 0.25 # noise_var is kept fixed\n",
        "eta = 0.01 # learning rate is kept fixed\n",
        "epsilon = 0.5 # min_change_nrmse is kept fixed\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, weights, bias, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, weights, bias, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, weights, bias, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, weights, bias, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, weights, bias, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, weights, bias, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, weights, bias, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, weights, bias, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, weights, bias, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, weights, bias, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, weights, bias, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, weights, bias, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, weights, bias, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, weights, bias, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, weights, bias, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, weights, bias, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, weights, bias, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, weights, bias, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, weights, bias, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, weights, bias, noise_variance)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data1, t1, eta, 10, epsilon, 0, 0)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data2, t2, eta, 100, epsilon, 0, 0)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data3, t3, eta, 1000, epsilon, 0, 0)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data4, t4, eta, 10000, epsilon, 0, 0)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data5, t5, eta, 100000, epsilon, 0, 0)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data6, t6, eta, 1000000, epsilon, 0, 0)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data7, t7, eta, 10000000, epsilon, 0, 0)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data8, t8, eta, 100000000, epsilon, 0, 0)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data9, t9, eta, 1000000000, epsilon, 0, 0)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data10, t10, eta, 10000000000, epsilon, 0, 0)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZwdBNeBSbLO5",
        "outputId": "7579e392-d9ac-46cb-d8af-76bcd8c22fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb1b736220>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.  Spread for Validation_NRMSE > Spread for Training_NRMSE\n",
        "2.  Mean for Validation_NRMSE > Mean for Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "As I am training the model on the training dataset for large number of iterations (by increasing max_iter and setting epsilon to 0), the model is possibly overfitting. Hence, it would not be able to generalize well on unseen data i.e. the validation dataset which also explains when the mean of the Validation_NRMSE > mean of theTraining_NRMSE"
      ],
      "metadata": {
        "id": "wjO7dXvV-v6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 13 (h) : Training and validation NRMSE obtained using gradient descent with eta"
      ],
      "metadata": {
        "id": "24xy3iJq2bMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will vary the value of eta from 1 to 0.000000001\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension) # w is kept fixed\n",
        "bias = 1 # bias is kept fixed\n",
        "noise_variance = 0.25 # noise_var is kept fixed\n",
        "max_iter = 1000 # max_iter is kept fixed\n",
        "epsilon = 0.5 # min_change_nrmse is kept fixed\n",
        "Lambda = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, weights, bias, noise_variance)\n",
        "v1 = generateTargetVector(validation_data1, weights, bias, noise_variance)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, weights, bias, noise_variance)\n",
        "v2 = generateTargetVector(validation_data2, weights, bias, noise_variance)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, weights, bias, noise_variance)\n",
        "v3 = generateTargetVector(validation_data3, weights, bias, noise_variance)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, weights, bias, noise_variance)\n",
        "v4 = generateTargetVector(validation_data4, weights, bias, noise_variance)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, weights, bias, noise_variance)\n",
        "v5 = generateTargetVector(validation_data5, weights, bias, noise_variance)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, weights, bias, noise_variance)\n",
        "v6 = generateTargetVector(validation_data6, weights, bias, noise_variance)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, weights, bias, noise_variance)\n",
        "v7 = generateTargetVector(validation_data7, weights, bias, noise_variance)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, weights, bias, noise_variance)\n",
        "v8 = generateTargetVector(validation_data8, weights, bias, noise_variance)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, weights, bias, noise_variance)\n",
        "v9 = generateTargetVector(validation_data9, weights, bias, noise_variance)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, weights, bias, noise_variance)\n",
        "v10 = generateTargetVector(validation_data10, weights, bias, noise_variance)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data1, t1, 1, max_iter, epsilon, 0, 0)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data2, t2, 0.1, max_iter, epsilon, 0, 0)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data3, t3, 0.01, max_iter, epsilon, 0, 0)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data4, t4, 0.001, max_iter, epsilon, 0, 0)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data5, t5, 0.0001, max_iter, epsilon, 0, 0)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data6, t6, 0.00001, max_iter, epsilon, 0, 0)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data7, t7, 0.000001, max_iter, epsilon, 0, 0)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data8, t8, 0.0000001, max_iter, epsilon, 0, 0)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data9, t9, 0.00000001, max_iter, epsilon, 0, 0)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data10, t10, 0.000000001, max_iter, epsilon, 0, 0)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "HF-_UvK52iZG",
        "outputId": "897d585a-a446-477b-d555-1bca012df658"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11a18b95b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "1.  Mean for Validation_NRMSE > Mean for Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "A smaller learning rate makes the model converge slowly to the global minimum loss and hence would require more training epochs (more time to train) due to the smaller changes made to the weights in every update, whereas a larger learning rate would result in rapid changes and hence require fewer training epochs. However, if the learning rate is too large then it might not be ever able to converge to the global minimum loss and might keep oscillating about that point."
      ],
      "metadata": {
        "id": "zwxMh1bQ_05_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13 (i) : Time taken to solve gradient descent with number of samples and number of variables and its breaking points"
      ],
      "metadata": {
        "id": "eO0--BhW4HLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep max_iter fixed and eta -> small \n",
        "# Varying the number of samples\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension)\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "\n",
        "max_iter = 1000\n",
        "eta = 0.01\n",
        "epsilon = 0\n",
        "Lambda1 = 0\n",
        "Lambda2 = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(10)\n",
        "x1 = generateDataMatrix(10, featureDimension)\n",
        "t1 = generateTargetVector(x1, weights, bias, noise_variance)\n",
        "\n",
        "x2 = generateDataMatrix(100, featureDimension)\n",
        "t2 = generateTargetVector(x2, weights, bias, noise_variance)\n",
        "\n",
        "x3 = generateDataMatrix(1000, featureDimension)\n",
        "t3 = generateTargetVector(x3, weights, bias, noise_variance)\n",
        "\n",
        "x4 = generateDataMatrix(10000, featureDimension)\n",
        "t4 = generateTargetVector(x4, weights, bias, noise_variance)\n",
        "\n",
        "x5 = generateDataMatrix(100000, featureDimension)\n",
        "t5 = generateTargetVector(x5, weights, bias, noise_variance)\n",
        "\n",
        "x6 = generateDataMatrix(1000000, featureDimension)\n",
        "t6 = generateTargetVector(x6, weights, bias, noise_variance)\n",
        "\n",
        "x7 = generateDataMatrix(10000000, featureDimension)\n",
        "t7 = generateTargetVector(x7, weights, bias, noise_variance)\n",
        "\n",
        "\n",
        "time_samples = []\n",
        "\n",
        "start = time.time()\n",
        "w_t1, nrmse_t1 = estimateLRweights(x1, t1, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t2, nrmse_t2 = estimateLRweights(x2, t2, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t3, nrmse_t3 = estimateLRweights(x3, t3, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t4, nrmse_t4 = estimateLRweights(x4, t4, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t5, nrmse_t5 = estimateLRweights(x5, t5, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t6, nrmse_t6 = estimateLRweights(x6, t6, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t7, nrmse_t7 = estimateLRweights(x7, t7, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_samples.append(end-start)\n",
        "\n",
        "time_samples = np.array(time_samples)\n",
        "n_samples = np.array([10, 100, 1000, 10000, 100000, 1000000, 10000000]) # Google Colab crashes when I use n_sample = 100000000 => breaking point is 100000000\n",
        "\n",
        "plt.plot(n_samples, time_samples)\n",
        "plt.title(\"Time Taken for Gradient Descent v/s Number of Samples\")\n",
        "plt.xlabel(\"Number of Samples\")\n",
        "plt.ylabel(\"Time Taken for Gradient Descent\")\n"
      ],
      "metadata": {
        "id": "WxmGPj0H4P7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "3aa83a7e-eeb7-403b-d745-a0e0b0ae7a98"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Time Taken for Gradient Descent')"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3ddZQcZdbH8e9v4h6ixEPcgWRICLJ4CBoIbkGCLfDCYrsEWILLArvsLu7uG0KwBA0eiACZuCtxt0lG7vtH1SzN7EjNTPf0yP2cM2e6n6quulVd3bfqqepbMjOcc865okhJdgDOOefKH08ezjnnisyTh3POuSLz5OGcc67IPHk455wrMk8ezjnniqzSJA9J0yUdnOw48iLpeUl3lsJ8TpS0VNJWSXsnen7xImm8pAvDx2dJ+jjZMbnkKq3PTD7zlqTnJG2Q9GMyYohKkknqlIhpV5jkEX4h5vxlS9oR8/wsM+tpZuMTHMPjMfPcJSkj5vlHiZx3RA8AV5hZXTP7KR4TlHSEpC8kbZG0TtLPkv4iqWY8pp+bmb1iZoPiMa3CPliSzpOUFfMeLgy/NLrEY/6JIGmRpMNLOI0zJL1ajPmullQnpu1CSeNLEksZdQBwBNDazPrnHiipuqQHJS0Lt5tFkh4q/TATq8Ikj/ALsa6Z1QWWAMfFtL1SSjFcGhPD3cAbMTEcVRoxFKIdML04L5RUJY+2U4C3gVeBdmbWGDgNaA20yWc6VYsz/yT6Pnw/GwCHAzuAyZJ6JTeshDoG+LAYr6sCXBXnWBIur227EO2ARWa2LZ/hI4BUoD9QDzgYmFLsAMsqM6twf8Ai4PD82oBbgbeAl4EtQBrQheBNXw0sBQbFvLYB8AywAlgO3AlUKSSGW4GXY56/BawENgFfAT1jhj0P3Bk+rgd8AfwLENAN+ARYD8wGTs31ukeAD8Ll+AHomEcsNYCtgAHbgPlhe3dgPLCRIKkcn2vajxF8iWzLY30qXE/XRlgPb4frejNwIcGH6vtwviuAh4HqMa85ApgVrquHgS+BC8Nh5wHfxIxbrPUTvgc562MrcFoesf9uXjHt7wNvxzzfF/guXJ5fgINzTWNBOP+FwFkxwy4CZobDZgB9w/aWwH+ANeFrrsy1Pt8EXgxfNx1IDYe9BGQTJLitwJ/ziH0mcGzM86rhfHLmnQKsApoANcP3bV24bBOB5gV85m4I34eGYduFwPjwcftwfVeNec34XO/rt8A/wnktAPYL25cSfC7PzfXePh6+91vCbaRdEbaLfLftmPdgTPj6ecBFYftwIB3ICtfxbflsH38q4DNxAzA/5n0/Mdf2Es/1YECnmO+BBwh2rleFr6sVDmsSxr0xXOavgZQCP9uFfRGXxz+iJY904EiCD8+LBB/Sm4BqBB/qhTGvfQd4AqgDNAN+BC4pJIZb+X3yuIAgMdQAHgJ+zrUB3Ak0Dqedk0jqhBvM+WGcewNrgR4xr1tH8GVcFXgFeL2AmGI3pGrhh+JGoDpwaLjxdY2Z9iZgf4IvlJq5ptUtnF77COshAzghnE4toB/BF25Vgi+VmYQftnAj3gKcHMZ4NZBJHsmjpOsndn3kE/t/55Wr/QJgVfi4VTiPo8PlOyJ83jSMb3PMOm1BuNMAnEKwI7IPQSLuRLBHmwJMBm4J35cOBF8gR+bado8m2NO/B5hQ0LafK/ZbgFdinh8DzIx5vi/B0RbAJcB7QO1wXv2A+gV95oBR/Lb9FjV5ZIbvZRWCz8MSguRfAxgUbhd1Y97bLcAfwuH/LOJ2ke+2HY7zFfAoQQLdiyDBHlrQdhHz2pvD2C8DegPKNfwUguSUQnCkvg1oEe/1kMdn/h8ECbERwXfRe8A94bB7CJJJtfDvwNxx/89yxuPLuqz9ES15fBIz7DiCvYgq4fN64UpvCDQHdhJm6HD4GcAXhcRwKzHJI9ewhuH0G8RsAM8C04DrY8Y7Dfg612ufAEbGvO7pmGFHA7MKiCl2QzqQ4EgoJWb4a8CtMdN+sYBpHRBOr2ZM2+sEey7bgXNi1sNXhayrPwHvhI+H8fsvQwHLyDt5lGj9UPzkMRjICB//BXgp1/BxwLkEX2IbgZNit5+Yca7KY9oDgCW52kYAz8Wsz09jhvUAdhS07eeaVieCL5va4fNXgFtiht8B/DV8fAHBEVWfqJ85oBfBF3NTip485sYM6x2O3zymbR2wV8x7G7sjUJfgaKBNxO2ioG27TTitejFt9wDPF7RdxIxbBbic4AhiJ/ArMUcLeYz/MzAk3ushdhsn+BxtI6ZnAhhIuJMM3A68SwGfh9x/FeacRzGsinm8A1hrZlkxzyF4I9oRZOIVkjZK2kiwITaLOiNJVSTdK2m+pM0EHzQI9rJzHEOwV/54TFs7YEDOfMN5nwXsHjPOypjH28OYo2gJLDWz7Ji2xQR70jmWFvD6deH/FjkNZna6mTUk6N+N7Uf+3XQkdZH0vqSV4fq4m9/WRcvY8S3YsvOLI5HrpyCtCA7tc2I4JVcMBxDsSW4j+CK7lGD7+UBSt/B1bQi6LvJappa5pncjwU5MfstUM+q5JDObR3Ckd5yk2sDxBOeschzNb+c7XiJIcq9L+lXS3yRVK2T60wi6P26IEk8uuT+TmFnuttj3L3Y72UrwnrQk2nZR0LbdElhvZlti2nJ/NvJlZllm9oiZ7U+wo3gX8Kyk7gCShoUXluTE1ovffxfEaz3EakpwBDk5Zr5jw3aA+wl6Ij6WtEBSoe9feTt5mQxLCfYemphZZjGncSYwhGDPbBHBOZQNBHsDOZ4CdgM+lDQ4/OJZCnxpZkcUc74F+RVoIyklJoG0BebEjGMFvH42QbfLUODBQuaVezqPAT8BZ5jZFkl/IuimguAcyH9PtksS+Zx8J7HrpyAnEvQJ58TwkpldlNeIZjYOGCepFkEXxFMER31LgY55vGQpwd5g52LGVtB7luM1gqPnFGBGmFCQtDvBzsCUMPYM4DbgNkntCZLKbILzfwUZGU4jdrvIOblcm6ArD37/ZV4csdtJXYLumF+Jtl0UtJ5+BRpJqheTQNoSbO9FYmY7gEck3Qb0kLSdYBs4jKB7MEvSz/z+u6Co8lsPsdYSJJ2eZvY/yxEu57XAteHFIJ9Lmmhmn+U308p85BGJma0APgYelFRfUoqkjpIOKsJk6hEkoHUEH5678xnvCoIP53vhl837QBdJ50iqFv7tk7MHU0I/EOy1/jmc7sEE3XevR3lxmHCuBUZKukjSbgp05vd7yXmpR/AFsjXcE/9jzLAPgJ6ShoZ701eS/5dMSdfPKoJzCoUKjx73kPRvgqtnbgsHvUywF39kOE5NSQdLai2puaQh4eWrOwm6RnMS9dPAdZL6heutk6R2BOe8tii43LlWOM1ekvaJ4zK9TtB3/kd+f9RxFDA2PNpD0iGSeodXI20mOHeVnXtiuYXJ6A2C9y6nbQ3Bl+/Z4TJdQN7JsyiOlnSApOoE3W0TzGwpJdwuwml8B9wTvp99CE6Uvxzl9ZL+FG4DtSRVlXQuwTb/E0FXphGcQ0HS+QRHHiWR33qIXaZsgqT1D0nNwnm3knRk+PjYcBsUQbdjFoW81548ohlGcPJyBsERw9vEdNdE8CLBYe/ycBoT8hop/NBeTNDH/y7Bh3UQcDrBnsRK4D6CE2MlYma7CJLFUQR7JY8Cw8xsVhGm8QZwKnA2wd7eWoIrgZ4kuLosP9cRHI1tIdig34iZ5lqCE4r3EiTbzgR9x3nNfwslWz+3Ai+Eh/Gn5jPOQElbCb48xwP1gX3MLC2MYSnBUeWNBF8IS4HrCT5bKcA1YWzrgYMIE6WZvUXQnfFquB5GA43CrtNjCU7SLiRYp08THK1GcQ9wc7hM1+U1QrhD9D3BVTxvxAzKfYnu7gTb+maCrq4vCbqyorid4Isy1kUE62Yd0JPgC7okXiU4yllPcDL/bIjLdgHBkVn78PXvEJwv+TTia7cTHHWtJHj/LgdOMrMFZjYjHPY9QaLvTT7bdxHkuR7y8BeCrqkJCrqLPwW6hsM6h8+3hrE9amZfFDRThTsZzrlKLDzKWwl0MLPNhY3vygZJzwPLzOzm0p63H3k45yDoJ/+rJw4XlZ8wd85hZqsJLmRwLhLvtnLOOVdk3m3lnHOuyCpkt1WTJk2sffv2yQ7DOefKlcmTJ681s6aFj1lBk0f79u2ZNGlSssNwzrlyRdLiqON6t5Vzzrki8+ThnHOuyDx5OOecKzJPHs4554rMk4dzzrki8+ThnHOuyDx5OOecKzJPHs45V0GMm76S139cUirzqpA/EnTOucpk5aZ0Ro6Zxrjpq+jbtiGnprYhJaUkNycsnCcP55wrp7KyjVd+WMzfxs4mIyubG47qxvAD9kh44gBPHs45Vy7NWrmZEaPS+GnJRg7s3IQ7T+hFu8a5b96YOJ48nHOuHEnPyOLfn8/liS8XUL9WNf5x2p6csFcrgtuPlx5PHs45V058O28tN72TxqJ12zmpb2tuOqY7jepUT0osnjycc66MW79tF3d9MJP/TFlG+8a1eeXCAezfqUlSY/Lk4ZxzZZSZMfrn5dzx/kw278jg8kM68n+HdqZmtSrJDs2Th3POlUWL123j5tHT+HruWvZu25B7hvam2+71kx3Wf3nycM65MiQjK5unv17IQ5/OoVqVFO4Y0pMzB7SjSilcflsUnjycc66M+HnpRm74z1RmrdzCkT2bc9vxvdi9Qc1kh5UnTx7OOZdkW3dm8sC42bzw/SKa1avB42f3Y3Cv3ZMdVoE8eTjnXBJ9MmMVt7w7jZWb0zln33Zcf2RX6tWsluywCuXJwznnkmDV5nRuHTOdj6atpGvzejxyVl/6tt0t2WFFlrCqupLaSPpC0gxJ0yVdFbY3kvSJpLnh/93Cdkn6l6R5kqZK6hszrXPD8edKOjdRMTvnXKJlZxsvT1jM4Q9+yWezVnP9kV15/8oDylXigMQeeWQC15rZFEn1gMmSPgHOAz4zs3sl3QDcAPwFOAroHP4NAB4DBkhqBIwEUgELpzPGzDYkMHbnnIu7Oau2MGJUGpMXb2C/jo2568Te7NGk9OpRxVPCkoeZrQBWhI+3SJoJtAKGAAeHo70AjCdIHkOAF83MgAmSGkpqEY77iZmtBwgT0GDgtUTF7pxz8ZSekcUjX8zj8S/nU7dGVR48ZU+G9i39elTxVCrnPCS1B/YGfgCah4kFYCXQPHzcClga87JlYVt+7bnncTFwMUDbtm3jF7xzzpXAd/PXctM701i4dhtD927FTcd0p3HdGskOq8QSnjwk1QX+A/zJzDbHZlozM0kWj/mY2ZPAkwCpqalxmaZzzhXXhm27uPvDmbw1eRltG9XmpeH9ObBz02SHFTcJTR6SqhEkjlfMbFTYvEpSCzNbEXZLrQ7blwNtYl7eOmxbzm/dXDnt4xMZt3POFZeZMeaXX7n9vRls3JHBHw/uyJWHdqZW9eTXo4qnQq+2knRKlLY8xhHwDDDTzP4eM2gMkHPF1LnAuzHtw8KrrvYFNoXdW+OAQZJ2C6/MGhS2OedcmbJk3XaGPfsjV73+M60b1ea9Kw7gL4O7VbjEAdGOPEYAb0Voy21/4BwgTdLPYduNwL3Am5KGA4uBU8NhHwJHA/OA7cD5AGa2XtIdwMRwvNtzTp4751xZkJmVzTPfLOQfn86hisStx/XgnIHty1w9qnjKN3lIOorgy7yVpH/FDKpPcBlugczsGyC/NXdYHuMbcHk+03oWeLaweTrnXGn7ZelGRoxKY8aKzRzevTm3D+lJy4a1kh1WwhV05PErMAk4Hpgc074FuDqRQTnnXFm3bWcmD348h+e/W0iTujV4/Oy+HNlz93J9+W1R5Js8zOwX4BdJr5pZRinG5JxzZdpnM1fx19HTWLE5nbMHtOP6wV2pXw7qUcVTlHMe/SXdCrQLxxdBL1OHRAbmnHNlzerN6dz23gw+SFtBl+Z1efvMgfRr1yjZYSVFlOTxDEE31WQgK7HhOOdc2ZOdbbw+cSn3fDSTnZnZXDeoCxf/oSPVqyasPGCZFyV5bDKzjxIeiXPOlUFzw3pUkxZvYGCHxtx1Yi86NK2b7LCSLkry+ELS/cAoYGdOo5lNSVhUzjmXZOkZWTw6fj6PjZ9HnRpVuf/kPpzcr3WlOSFemCjJY0D4PzWmzYBD4x+Oc84l34QF67jxnTQWrNnGCXu15OZje9CkAtSjiqdCk4eZHVIagTjnXLJt2p7BPR/N5PWJS2nTqBYvXNCfg7pUnHpU8VRo8pDUHLgbaGlmR0nqAQw0s2cSHp1zzpUCM+O9qSu4/b3pbNiewSUHdeBPh3WpkGVF4iVKt9XzwHPATeHzOcAbBFdhOedcubZ0/Xb++u40xs9eQ5/WDXjhgv70bNkg2WGVeVGSRxMze1PSCAAzy5Tkl+w658q1zKxsnv9uEQ9+PAcJbjm2B+fuV7HrUcVTlOSxTVJjgpPk5FS8TWhUzjmXQGnLNjHinalMW76Zw7o14/YTetGqEtSjiqcoyeMagnLpHSV9CzQFTk5oVM45lwDbdmby90/m8Ny3C2lctwaPntWXo3pVnnpU8RTlaqspkg4CuhKUJpntta6cc+XNF7NWc/PoaSzfuIMzB7TlL4O70aBW5apHFU9Rrra6nOBOgNPD57tJOsPMHk14dM45V0Krt6Rz+3szeH/qCjo1q8tblw5kn/aVsx5VPEXptrrIzB7JeWJmGyRdBHjycM6VWdnZxpuTlnL3hzNJz8jmmiO6cMlBHahR1S+/jYcoyaOKJIU3a0JSFaB6YsNyzrnim7d6KzeOSuPHRevpv0cj7hnam45ejyquoiSPscAbkp4In18StjnnXJmyMzOLx8bP59Ev5lOzWgr3ndSbU/q1IcUvv427KMnjL8DFwB/D558ATycsIuecK4YfF65nxKipzF+zjeP3bMlfj+1B03pejypRolxtlQ08DjwuqRHQ2sz8R4LOuTJh0/YM7h07k9d+XEqrhrV47vx9OKRrs2SHVeFFudpqPMF9zKsS3BBqtaTvzMzvY+6cSxoz44O0Fdw6Zgbrt+3k4j904E+Hd6Z29SgdKq6koqzlBma2WdKFwItmNlLS1EQH5pxz+Vm2YTu3vDudz2etpnerBjx//j70auX1qEpTlORRVVIL4FR+K47onHOlLivbwnpUszGDm4/pznn7tadqlcp7O9hkiZI8bgfGAd+a2URJHYC5iQ3LOed+b9ryTYwYlUba8k0c0rUpd5zQi9a71U52WJVWlBPmbwFvxTxfAJyUyKCccy7H9l2ZPPTpXJ75ZiG71a7Ow2fuzTG9W3g9qiSLcsK8C/AY0NzMeknqAxxvZncmPDrnXKU2fnZQj2rZhh2c0b8NNwzuToPaXo+qLIjSUfgUMALIADCzqcDpiQzKOVe5rdmykytf+4nznptIjaopvHnJQO4Z2scTRxkS5ZxHbTP7MdchYmaC4nHOVWJmxluTlnHXhzPZsSuLPx3emT8e3NHrUZVBUZLHWkkd+e1mUCcDKxIalXOu0lmwZis3vpPGhAXr6d++EXcP7UWnZvWSHZbLR5TkcTnwJNBN0nJgIXBWQqNyzlUauzKzefzL+Tz8xTxqVE3hnqG9OS3V61GVdVGutloAHC6pDpBiZlsSH5ZzrjKYtGg9I0alMXf1Vo7t04JbjutBs3o1kx2Wi6DA5CGpK0FRxG5h00xJT5rZnIRH5pyrsDbtyOC+sbN49YcltGpYi2fPS+XQbs2THZYrgnyTh6SBwCjgCYJuKwF7A+MlDTWzCaUTonOuojAzPpq2kpFjprNu606GH7AH1xzRhTo1vB5VeVPQO3YLcIaZjY9pGy3pc2AkcFQiA3POVSy/btzBLe9O49OZq+nZsj7PnrsPvVt7ParyqqDk0TFX4gDAzL6U9GTiQnLOVSRZ2cYLYT2qbIObju7O+ft7ParyrqDkUdCJ8W3xDsQ5V/FM/3UTN45K45dlmzioS1PuPKEXbRp5PaqKoKDk0UbSv/JoF9AqQfE45yqAHbuyeOizOTz99UIa1qrGP0/fi+P3bOn1qCqQgpLH9QUMm1TYhCU9CxwLrDazXmHbrcBFwJpwtBvN7MNw2AhgOJAFXGlm48L2wcA/gSrA02Z2b2Hzds4lz1dz1nDT6DSWrt/BaaltGHF0NxrWrp7ssFyc5Zs8zOyFEk77eeBh4MVc7f8wswdiGyT1IKiX1RNoCXwaFmQEeAQ4AlgGTJQ0xsxmlDA251ycrd26kzvfn8Hon3+lQ5M6vHbRvgzs2DjZYbkESdj1cWb2laT2EUcfArxuZjuBhZLmAf3DYfPCHyoi6fVwXE8ezpURZsbbk4N6VNt2ZnLloZ247JBO1Kzm9agqsmRcXH2FpGEEXV/XmtkGgnMosb8bWcZv51WW5mofkNdEJV1M8ING2rZtG++YnXN5WLh2GzeOSuP7BetIbbcb9wztTefmXo+qMij0WjlJ+0dpi+gxoCOwF0FxxQeLOZ3/YWZPmlmqmaU2bdo0XpN1zuVhV2Y2D38+lyMf+oppv27irhN78eYlAz1xVCJRjjz+DfSN0FYoM1uV81jSU8D74dPlQJuYUVuHbRTQ7pxLgsmLNzBi1FTmrNrKMb1bMPK4HjSr7/WoKpvCypPsBzSVdE3MoPoEVz4VmaQWZpZTzv1EYFr4eAzwqqS/E5ww7wz8SHBZcGdJexAkjdOBM4szb+dcyWxOz+D+sbN5+YfFtKhfk6eHpXJ4D69HVVkVdORRHagbjhN7LLoZOLmwCUt6DTgYaCJpGUFJk4Ml7UVwb5BFwCUAZjZd0psEJ8IzgcvNLCuczhXAOIKE9ayZTS/C8jnn4mDstJWMHDON1Vt2ct5+7bl2UFfqej2qSk1mVvAIUjszW1xK8cRFamqqTZpU6E9RnHOFWLFpB7e8O51PZqyie4v63Du0N3u2aZjssFyCSJpsZqlRxo2y61AjrGXVPnZ8Mzu0eOE558q6rGzj5QmLuX/cbDKzsxlxVDcuOGAPqnk9KheKkjzeAh4Hnib49bdzrgKbuWIzI0al8fPSjRzYuQl3ndCbto29HpX7vSjJI9PMHkt4JM65pErPyOKfn83lqa8W0KBWNR46bS+G7OX1qFzeoiSP9yRdBrwD7MxpNLP1CYvKOVeqvpm7lptGp7F43XZO6deaG4/uzm51vB6Vy1+U5HFu+D+2UKIBHeIfjnOuNK3bupO7PpjJqJ+W075xbV69cAD7dWqS7LBcOVBo8jCzPUojEOdc6TEzRk1Zzp0fzGBLeiZXHNKJKw71elQuukKTh6TawDVAWzO7WFJnoKuZvV/IS51zZdCitdu4aXQa385bR9+2DblnaB+67u5lRVzRROm2eg6YTPBrcwh+6f0Wv5UWcc6VAxlZ2Tz51QL+9dlcqldJ4Y4TenFW/7akpPgJcVd0UZJHRzM7TdIZAGa2XX75hXPlypQlG7hxVBqzVm5hcM/dufX4nuzewOtRueKLkjx2SapFcJIcSR2JuerKOVd2bUnP4IFxs3lxwmKa16vJk+f0Y1DP3ZMdlqsAoiSPkcBYgnuavwLsD5yXyKCccyU3bvpKRr47nVVb0jl3YHuuHdSFejWrJTssV0FEudrqE0lTgH0JqtxeZWZrEx6Zc65YVm5KZ+SYaYybvopuu9fjsbP7snfb3ZIdlqtgCirJ3s3MZknKuW9HTin1tpLamtmUxIfnnIsqO9t45YfF3Dd2NhlZ2fx5cFcuOrCD16NyCVHQkce1wEXkfbc/A7wwonNlxOyVWxgxaipTlmzkgE5NuOvEXrRrXCfZYbkKLN/kYWYXhf8PKb1wnHNFkZ6Rxb8/n8sTXy6gXs2q/P3UPTlx71Zej8olXEHdVkMLeqGZjYp/OM65qL6bt5Yb30lj0brtnNS3NTcd051GXo/KlZKCuq2OC/83I/iB4Ofh80OA7wBPHs4lwYZtu7jrw5m8PXkZ7RrX5pULB7C/16NypaygbqvzASR9DPTIufe4pBbA86USnXPuv8yM0T8v5473Z7J5RwaXHdyRKw/r7PWoXFJE+Z1Hm5zEEVoFtE1QPM65PCxZt52bRqfx9dy17NWmIfee1Jtuu9dPdliuEouSPD6TNA54LXx+GvBp4kJyzuXIyMrmmW8W8tCnc6iaksLtQ3py1oB2VPF6VC7JovxI8Irw5PmBYdOTZvZOYsNyzv28dCM3/Gcqs1ZuYVCP5tw2pCctGtRKdljOAdGOPHKurPIT5M6Vgq07M3lg3Gxe+H4RzerV4PGz+zG4l9ejcmVLlPt57Av8G+gOVAeqANvMzDtcnYuzT2as4pZ3p7Fyczrn7NuO647sSn2vR+XKoChHHg8DpxPcwyMVGAZ0SWRQzlU2qzanc+uY6Xw0bSVdm9fj4TP70q+d16NyZVfUbqt5kqqYWRbwnKSfgBGJDc25ii8723j1xyXc99EsdmZlc/2RQT2q6lW9HpUr26Ikj+2SqgM/S/obQYFE37KdK6E5q7YwYlQakxdvYL+OjbnrxN7s0cTrUbnyIUryOIcgWVwBXA20AU5KZFDOVWTpGVk88sU8Hv9yPnVqVOWBU/bkpL5ej8qVLwUmD0lVgLvN7CwgHbitVKJyroL6fv46bnwnjYVrt3Hi3q24+ZjuNK5bI9lhOVdkBSYPM8uS1E5SdTPbVVpBOVfRbNy+i7s/nMmbk5bRtlFtXhrenwM7N012WM4VW5RuqwXAt5LGANtyGs3s7wmLyrkKwswY88uv3P7eDDbuyODSgzpy1WGdqVXd61G58i1K8pgf/qUA9RIbjnMVx9L127lp9DS+mrOGPVs34KXhA+jR0n8e5SqGKOVJ/DyHc0WQmZXNs98u5O+fzKGKxMjjejBsYHuvR+UqlIJuBnUA0MHMXgyfvw00CgffaWaf5/da5yqrqcs2csN/0pixYjOHd2/G7UN60bKh16NyFU9BRx63Af8X87wrcB5QB7iR324O5Vylt21nJg9+PIfnv1tIk7o1eOysvgzutbtffusqrIKSR30zmxHzfK6ZTQaQdE9iw3Ku/Ph81ir+Ono6yzfu4Ox92/Lnwd28HpWr8ApKHg1jn5hZ7D3NmycmHOfKj9Vb0rntvRl8MHUFnZvV5e1LB5LavlHhL3SuAjzZEp8AABpVSURBVCiozMgsScfkbpR0LDC7sAlLelbSaknTYtoaSfpE0tzw/25huyT9S9I8SVMl9Y15zbnh+HMlnVu0xXMu/rKzjVd/WMJhD37JJzNWcd2gLnxw5YGeOFylUtCRx9XAB5JOBqaEbf2A/YBjI0z7eYKKvC/GtN0AfGZm90q6IXz+F+AooHP4NwB4DBggqREwkqCarwGTJY0xsw3RFs+5+Jq3OqhHNXHRBvbt0Ii7T+xNh6Z1kx2Wc6Uu3+QRVtLtA5wF9AybvwIuNbP0wiZsZl9Jap+reQhwcPj4BWA8QfIYArxoZgZMkNRQUotw3E/MbD2ApE+Awfx2S1znSkV6RhaPjp/PY+PnUbt6Vf52ch9O6dfaT4i7Squw8iQ7gWfjOL/mZrYifLyS386dtAKWxoy3LGzLr/1/SLoYuBigbdu2cQzZVXYTFgT1qBas2caQvVry12N70MTrUblKLtL9PBLBzEySxXF6TwJPAqSmpsZtuq7y2rQ9g3s+msnrE5fSerdavHBBfw7q4vWonIPSTx6rJLUwsxVht9TqsH05Qan3HK3DtuX81s2V0z6+FOJ0lZiZ8d7UFdz+3nQ2bM/gkj904KrDO1O7etL2tZwrcwq8qZOkKpJeieP8xgA5V0ydC7wb0z4svOpqX2BT2L01DhgkabfwyqxBYZtzCbF0/XbOf34iV772Ey0a1OLdy/dnxNHdPXE4l0vCSrJLeo3gqKGJpGUEV03dC7wpaTiwGDg1HP1D4GhgHrAdOD+c/3pJdwATw/Fuzzl57lw8ZWZl8/x3i3jw4zlIcMuxPTh3P69H5Vx+FFzgVMAI0otAd4Kjg3JRkj01NdUmTZqU7DBcOZG2bBMj3pnKtOWbObRbM+44oRetvB6Vq4QkTTaz1Cjjekl2V2lt25nJPz6Zw7PfLqRRnRo8cmZfju7t9aiciyJySXZJdcPnWxMdlHOJ9sWs1dw8ehrLN+7gjP5tuWFwNxrU9npUzkVVaPKQ1At4ibAcu6S1wDAzm57g2JyLuzVbdnL7+zN475df6dSsLm9dOpB9vKyIc0UWpdvqSeAaM/sCQNLBwFMEZUqcKxeys403Jy3l7g9nkp6RzdWHd+HSgztQo6rfDta54oiSPOrkJA4AMxsvqU4CY3Iuruat3sqN76Tx48L19N8jqEfVqZnXo3KuJKIkjwWS/krQdQVwNrAgcSE5Fx87M7N4fPwCHvliHjWrpXDfSb05pV8bUvzyW+dKLEryuIDgroKjCCrbfh22OVdm/bhwPSNGTWX+mm0ct2dL/npsd5rVq5nssJyrMAq6h/lLZnYOwcnxK0sxJueKbdOODO79aBav/biEVg1r8dx5+3BIt2bJDsu5CqegI49+kloCF4Q/FPzdsb7/0tuVJWbGh2krufW96azbupMLD9iDq4/oQp0aXlbEuUQo6JP1OPAZ0AGYzO+Th4XtziXd8o07uGX0ND6btZpererz7Ln70Lt1g2SH5VyFVtDNoP4F/EvSY2b2x1KMyblIsrItrEc1GzO4+ZjunLdfe6pWKbDep3MuDqL8wtwThytzpi3fxI3vpDF12SYO7tqUO4b0ok2j2skOy7lKwzuEXbmyfVcmD306l2e+Wchutavx7zP25tg+LbwelXOlzJOHKzfGzw7qUS3bsIMz+rfhhsHdvR6Vc0niycOVeWu27OSO92cw5pdf6dC0Dm9cvC8DOjROdljOVWpRCiMOBe4DmhFccSWCW5DXT3BsrpIzM96atIy7PpzJ9l2ZXHVYZy47pKPXo3KuDIhy5PE34Dgzm5noYJzLsWBNUI9qwoL17NN+N+4Z2ptOzfx2Ms6VFVGSxypPHK607MrM5okv5/PvL+ZRo2oK9wztzWmpXo/KubImSvKYJOkNYDSwM6fRzEYlLCpXKU1atJ4Ro9KYu3orx/Rpwchje9Csvtejcq4sipI86gPbgUExbUZQKNG5Etu0I4O/jZ3FKz8soWWDmjxzbiqHdW+e7LCccwWI8iPB80sjEFf5mBljp61k5JjprN26k+EH7ME1Xo/KuXIhytVWXYDHgOZm1ktSH+B4M7sz4dG5CuvXjTu45d1pfDpzNT1a1Ofpc1Pp07phssNyzkUUZRfvKeB64AkAM5sq6VXAk4crsqxs48XvF/HAuNlkmXHj0d24YP89vB6Vc+VMlORR28x+zFX+ITNB8bgKbMavmxkxaiq/LNvEH7o05a4TvB6Vc+VVlOSxVlJHgpPkSDoZWJHQqFyFsmNXFv/8bC5Pfb2AhrWq8c/T9+L4PVt6PSrnyrEoyeNy4Emgm6TlwELgrIRG5SqMr+as4abRaSxdv4NTU1tz49HdaVi7erLDcs6VUJTksZuZHS6pDpBiZlskHQssTnBsrhxbt3Und34wk3d+Ws4eTerw6kUD2K9jk2SH5ZyLk0gnzCUNM7NpAJJOB64G3k9oZK5cMjP+M2U5d34wg207M7ny0E5cdkgnalbzelTOVSRRksfJwNuSzgQOBIbx+x8MOgfAwrXbuOmdNL6bv45+7YJ6VF2aez0q5yqiKD8SXBAebYwGlgCDzGxHwiNz5cauzGye+noB//xsLjWqpHDnCb04s39br0flXAWWb/KQlEZ4hVWoEVAF+EESZtYn0cG5sm/y4g3cOCqN2au2cHTv3Rl5XE+aez0q5yq8go48ji21KFy5szk9g/vHzublHxaze/2aPDUslSN6eD0q5yqLfJOHmf3uaipJzQDfpXRhPapprN6yk/P2a8+1g7pS1+tROVepRKltdTzwINASWA20A2YCPRMbmitrVmzawS3vTueTGavo3qI+T5yTyl5tvB6Vc5VRlN3FO4B9gU/NbG9JhwBnJzYsV5ZkZRsvT1jM/eNmk5mdzQ1HdWP4AXtQzetROVdpRUkeGWa2TlKKpBQz+0LSQwmPzJUJM1dsZsSoNH5eupEDOzfhrhN607ax16NyrrIr6GqrK8zsYWCjpLrAV8ArklYD20oyU0mLgC1AFpBpZqmSGgFvAO2BRcCpZrZBQQGkfwJHE9yU6jwzm1KS+bvCpWeE9ai+WkD9WtV46LS9GLKX16NyzgUK6ne4IPw/BNhB8KvyscB84Lg4zPsQM9vLzFLD5zcAn5lZZ+Cz8DnAUUDn8O9ignuLuAT6Zu5ajnzoKx4bP58T9m7FZ9ccxAl7t/LE4Zz7ryg/Eow9ynghgbEMAQ6Omc944C9h+4tmZsAESQ0ltTAzr+wbZ+u37eLOD2Ywaspy2jeuzasXDmC/Tl6Pyjn3vwpKHn0kbc6jXYCZWf0SzNeAjyUZ8ISZPUlwp8KchLASyPnRQCtgacxrl4VtnjzixMwYFdaj2pKeyRWHdOKKQ70elXMufwUljzQz2ztB8z3AzJaHvx35RNKs2IFmZmFiiUzSxQTdWrRt2zZ+kVZwi9Zu46bRaXw7bx17t23IvUP70HV3r0flnCtYUn7ZZWbLw/+rJb0D9AdW5XRHSWpB8JsSgOVAm5iXtw7bck/zSYL7jpCamlqkxFMZZWSF9ag+nUu1KincMaQnZw1o5/WonHORFHTC/K1EzFBSHUn1ch4TVOidBowBzg1HOxd4N3w8BhimwL7AJj/fUTI/LdnAcf/+hr+Nnc0hXZvx6TUHcc7A9p44nHORFVSe5O4EzbM58E545U5V4FUzGytpIvCmpOEEN5o6NRz/Q4LLdOcRXKp7foLiqvC2pGfwwLjZvDhhMc3r1eSJc/pxZM/dkx2Wc64cKvVuKzNbAOyZR/s64LA82o3gVriuBD6evpJb3p3Oqi3pDNu3Hdcd2ZV6NaslOyznXDnl1ewquJWb0rl1zHTGTl9J1+b1ePTsvvRtu1uyw3LOlXNRCiM2B+4GWprZUZJ6AAPN7JmER+eKLTvbeOWHxfxt7Gx2ZWXz58FduejADl6PyjkXF1GOPJ4HngNuCp/PISgj4smjjJq9cgsjRk1lypKN7N+pMXed0Jv2TeokOyznXAUSJXk0MbM3JY0AMLNMSVkJjssVQ3pGFg9/Po/Hv5xPvZpVefCUPRna18uKOOfiL0ry2CapMeEtaXMul01oVK7Ivpu3lhvfSWPRuu0M7duKm4/pQaM61ZMdlnOugoqSPK4h+K1FR0nfAk2BkxMalYtsw7Zd3PXhTN6evIx2jWvz8vABHNDZ61E55xIrSmHEKZIOAroS1LWabWYZCY/MFcjMGP3zcu54fyabd2Rw2cEdufKwzl6PyjlXKqJcbVWF4Ed67cPxB0nCzP6e4NhcPpas285No9P4eu5a9mrTkHuG9qZ7i5LUqXTOuaKJ0m31HpAOpAHZiQ3HFSQjK5tnvlnIQ5/OoWpKCrcd35Oz921HFS8r4pwrZVGSR2sz65PwSFyBflm6kRtGpTFzxWaO6NGc24f0pEWDWskOyzlXSUVJHh9JGmRmHyc8Gvc/tu7M5IFxs3nh+0U0q1eDx8/ux+BeXo/KOZdcUZLHBIJChilABvG5GZSL4NMZq/jru9NYuTmdswe04/rBXanv9aicc2VAlOTxd2Agwc2h/D4ZpWD15nRufW86H6atpEvzujx85n70a+f1qJxzZUeU5LEUmOaJI/Gys41Xf1zCfWNnsTMzm+uPDOpRVa/q9aicc2VLlOSxABgv6SNgZ06jX6obX/PXbOXPb09l8uINDOzQmLuH9mYPr0flnCujoiSPheFf9fDPxdnXc9dw2ctTqFJF3H9yH07u19rrUTnnyrQovzC/rTQCqaxe+3EJN4+eRudmdXnmvH1o1dAvv3XOlX35Jg9JD5vZFZLeIyyKGMvMjk9oZBVcdrZx39hZPPHVAg7q0pSHz9zb7+znnCs3CjryGAZcATxQSrFUGjt2ZfGnN35i3PRVnLNvO0Ye14OqfpMm51w5UlDymA9gZl+WUiyVwurN6Vz44iTSlm/ir8f24IL92/v5DedcuVNQ8mgq6Zr8BvrVVkU3a+VmLnhuIht3ZPDUOakc3qN5skNyzrliKSh5VAHqEvyi3JXQ+NmrueLVn6hTowpvXjKQXq0aJDsk55wrtoKSxwozu73UIqnAXvp+ESPHTKfb7vV55rxUL2jonCv3CkoefsRRQlnZxl0fzOTZbxdyWLdm/OuMvalTI8pPa5xzrmwr6JvssFKLogLatjOTq17/iU9nrub8/dtz8zE9/L4bzrkKI9/kYWbrSzOQimTlpnSGvzCRmSs2c/uQngwb2D7ZITnnXFx5H0qcTVu+ieEvTGRreibPnLcPh3RtluyQnHMu7jx5xNGnM1Zx5es/0bBWNd7+435+X3HnXIXlySMOzIznvl3EnR/MoGfLBjxzbirN6tdMdljOOZcwnjxKKDMrm9vfn8GL3y9mUI/mPHT6XtSu7qvVOVex+bdcCWxJz+D/XvuJ8bPXcPEfOnDD4G6k+BVVzrlKwJNHMS3fuIPhz09k7uqt3H1ib84c0DbZITnnXKnx5FEMU5dtZPgLk0jflcVz5+3DH7o0TXZIzjlXqjx5FNG46Su56vWfaFynBq9cNoAuzeslOyTnnCt1njwiMjOe+noB93w0iz1bN+SpYak0rVcj2WE551xSePKIICMrm5FjpvPqD0s4pncLHjx1T2pWq5LssJxzLmk8eRRic3oGl78yha/nruWygzty3aCufkWVc67SKzf3PpU0WNJsSfMk3VAa81y6fjsnPfod389fx99O6sOf/VJc55wDysmRh6QqwCPAEcAyYKKkMWY2I97zMjOmLtvEf6YsY/RPywF48YL+7NepSbxn5Zxz5Va5SB5Af2CemS0AkPQ6MASIa/JYt3Unxz/8Lcs37qBG1RSO6NGcq4/oQsemdeM5G+ecK/fKS/JoBSyNeb4MGBA7gqSLgYsB2rYt3g/2alevyp5tGnDFoZ04uncLGtSqVsxwnXOuYisvyaNQZvYk8CRAamqqFWcatapX4dGz+sU1Luecq4jKywnz5UCbmOetwzbnnHNJUF6Sx0Sgs6Q9JFUHTgfGJDkm55yrtMpFt5WZZUq6AhgHVAGeNbPpSQ7LOecqrXKRPADM7EPgw2TH4Zxzrvx0WznnnCtDPHk455wrMk8ezjnnisyTh3POuSKTWbF+T1emSVoDLC7BJJoAa+MUTnlR2Za5si0v+DJXFiVZ5nZmFunWqBUyeZSUpElmlprsOEpTZVvmyra84MtcWZTWMnu3lXPOuSLz5OGcc67IPHnk7clkB5AElW2ZK9vygi9zZVEqy+znPJxzzhWZH3k455wrMk8ezjnniqzSJg9JgyXNljRP0g15DK8h6Y1w+A+S2pd+lPEVYZmvkTRD0lRJn0lql4w446mwZY4Z7yRJJqncX9YZZZklnRq+19MlvVraMcZbhG27raQvJP0Ubt9HJyPOeJH0rKTVkqblM1yS/hWuj6mS+sY9CDOrdH8EZd3nAx2A6sAvQI9c41wGPB4+Ph14I9lxl8IyHwLUDh//sTIsczhePeArYAKQmuy4S+F97gz8BOwWPm+W7LhLYZmfBP4YPu4BLEp23CVc5j8AfYFp+Qw/GvgIELAv8EO8Y6isRx79gXlmtsDMdgGvA0NyjTMEeCF8/DZwmCSVYozxVugym9kXZrY9fDqB4I6N5VmU9xngDuA+IL00g0uQKMt8EfCImW0AMLPVpRxjvEVZZgPqh48bAL+WYnxxZ2ZfAesLGGUI8KIFJgANJbWIZwyVNXm0ApbGPF8WtuU5jpllApuAxqUSXWJEWeZYwwn2XMqzQpc5PJxvY2YflGZgCRTlfe4CdJH0raQJkgaXWnSJEWWZbwXOlrSM4L5A/1c6oSVNUT/vRVZubgblSo+ks4FU4KBkx5JIklKAvwPnJTmU0laVoOvqYIKjy68k9TazjUmNKrHOAJ43swclDQRektTLzLKTHVh5VVmPPJYDbWKetw7b8hxHUlWCQ911pRJdYkRZZiQdDtwEHG9mO0sptkQpbJnrAb2A8ZIWEfQNjynnJ82jvM/LgDFmlmFmC4E5BMmkvIqyzMOBNwHM7HugJkEBwYoq0ue9JCpr8pgIdJa0h6TqBCfEx+QaZwxwbvj4ZOBzC89ElVOFLrOkvYEnCBJHee8Hh0KW2cw2mVkTM2tvZu0JzvMcb2aTkhNuXETZtkcTHHUgqQlBN9aC0gwyzqIs8xLgMABJ3QmSx5pSjbJ0jQGGhVdd7QtsMrMV8ZxBpey2MrNMSVcA4wiu1HjWzKZLuh2YZGZjgGcIDm3nEZyYOj15EZdcxGW+H6gLvBVeG7DEzI5PWtAlFHGZK5SIyzwOGCRpBpAFXG9m5faoOuIyXws8JelqgpPn55XnnUFJrxHsADQJz+OMBKoBmNnjBOd1jgbmAduB8+MeQzlef84555KksnZbOeecKwFPHs4554rMk4dzzrki8+ThnHOuyDx5OOdcOVdYocRc4/5D0s/h3xxJxfpxqCcPV+6E1W8fjHl+naRb4zTt5yWdHI9pFTKfUyTNlPRFrvaUsBrqNElpkiZK2iPBsSwKf+/hyq/ngUhlZszsajPby8z2Av4NjCrODD15uPJoJzC0rH3hhZUIohoOXGRmh+RqPw1oCfQxs97AiUBFLhvi4iCvQomSOkoaK2mypK8ldcvjpWcArxVnnp48XHmUSVBi++rcA3IfOUjaGv4/WNKXkt6VtEDSvZLOkvRjuIffMWYyh0uaFB7SHxu+voqk+8MjgamSLomZ7teSxgAz8ojnjHD60yTdF7bdAhwAPCPp/lwvaQGsyKm5ZGbLcqrfSnosjGu6pNti5rFI0j1hN8QkSX0ljZM0X9KlMXF+JekDBfe9eDys7ZU73rPDdfKzpCfC5a4Srteco6H/We+uTHoS+D8z6wdcBzwaO1DB/Xr2AD4vzsQr5S/MXYXwCDBV0t+K8Jo9ge4Ee2gLgKfNrL+kqwiqrP4pHK89QZnvjsAXkjoBwwhKPOwjqQbwraSPw/H7Ar3COlH/JaklQan3fsAG4GNJJ5jZ7ZIOBa7LoxTKm8A3kg4EPgNeNrOfwmE3mdl6SVWAzyT1MbOp4bAlZraXpH8QdGHsT1CCYxrweDhOf4J7WSwGxgJDCW43kBNvd4Ijn/3NLEPSo8BZwHSglZn1CsdrGGFduySSVBfYj9+qRQDUyDXa6cDbZpZVnHn4kYcrl8xsM/AicGURXjbRzFaEBR/nAzlf/mkECSPHm2aWbWZzCZJMN2AQQa2gn4EfCMrz5xQT/DF34gjtA4w3szVhWf9XCG7iU9ByLQO6AiOAbIIkcVg4+FRJUwhu5NSTIBHkyCm1kkZw458tZrYG2BnzZf9jeM+LLIKuigNyzf4wgkQ3MVzOwwhusLQA6CDp3wrKt28uaBlcmZACbMw5txH+dc81zukUs8sK/MjDlW8PAVOA52LaMgl3isJumeoxw2KrBGfHPM/m95+F3DV7jOCObP9nZuNiB0g6GNhWvPDzFia3j4CPJK0CTpC0gKDrYR8z2yDpeYIjixyxy5J7OXOWLa/liiXgBTMbkTsmSXsCRwKXAqcCFxR1uVzpMbPNkhZKOsXM3lJw+NHHzH4BCM9/7AZ8X9x5+JGHK7fMbD1BN8/wmOZFBHvPAMcTFosrolPCq546Eux5zyYouvdHSdUAJHWRVKeQ6fwIHCSpSdjVdAbwZUEvCM9XtAwfpwB9CLqZ6hMkqU2SmgNHFWO5+iuoPJtC0D31Ta7hnwEnS2oWzr+RpHbhhQkpZvYf4GaCbjpXhigolPg90FXSMknDCboch0v6haDrMfbuiqcDr5ekOKQfebjy7kHgipjnTwHvhh+YsRTvqGAJwRd/feBSM0uX9DRB19aUcC9uDXBCQRMxsxWSbgC+INir/8DM3i1k3s0Iqr/m9E//CDwcxvATMIvgDnHfFmO5JgIPA53CmN7JFe8MSTcTnJtJATKAy4EdwHMxJ9j/58jEJZeZnZHPoDwv3zWzW0s6T6+q61wlEHavXWdmxyY7FlcxeLeVc865IvMjD+ecc0XmRx7OOeeKzJOHc865IvPk4Zxzrsg8eTjnnCsyTx7OOeeK7P8BYV5DOwqZe1AAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "1.  The plot between Taken Taken for Gradient Descent v/s Number of Samples starts non-linearly but quickly becomes linear\n",
        "2. The breaking point observed in this case was for Number of Samples = 100000000\n",
        "\n",
        "# Potential Reason :    \n",
        "As the number of samples increase, performing gradient descent increases linearly.\n",
        "The RAM of the virtual machine Google colab had assigned me crashes when the number of rows = number of samples = 100000000"
      ],
      "metadata": {
        "id": "hhnsSrs0BN08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VwGWNiqmBKwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep max_iter fixed and eta -> small \n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NumberOfSamples = 10\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "\n",
        "max_iter = 1000\n",
        "eta = 0.01\n",
        "epsilon = 0\n",
        "Lambda1 = 0\n",
        "Lambda2 = 0\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(10)\n",
        "x1 = generateDataMatrix(NumberOfSamples, 10)\n",
        "w1 = np.random.rand(1, np.shape(x1)[1])\n",
        "t1 = generateTargetVector(x1, w1, bias, noise_variance)\n",
        "\n",
        "x2 = generateDataMatrix(NumberOfSamples, 100)\n",
        "w2 = np.random.rand(1, np.shape(x2)[1])\n",
        "t2 = generateTargetVector(x2, w2, bias, noise_variance)\n",
        "\n",
        "x3 = generateDataMatrix(NumberOfSamples, 500)\n",
        "w3 = np.random.rand(1, np.shape(x3)[1])\n",
        "t3 = generateTargetVector(x3, w3, bias, noise_variance)\n",
        "\n",
        "x4 = generateDataMatrix(NumberOfSamples, 1000)\n",
        "w4 = np.random.rand(1, np.shape(x4)[1])\n",
        "t4 = generateTargetVector(x4, w4, bias, noise_variance)\n",
        "\n",
        "x5 = generateDataMatrix(NumberOfSamples, 2000)\n",
        "w5 = np.random.rand(1, np.shape(x5)[1])\n",
        "t5 = generateTargetVector(x5, w5, bias, noise_variance)\n",
        "\n",
        "x6 = generateDataMatrix(NumberOfSamples, 4000)\n",
        "w6 = np.random.rand(1, np.shape(x6)[1])\n",
        "t6 = generateTargetVector(x6, w6, bias, noise_variance)\n",
        "\n",
        "x7 = generateDataMatrix(NumberOfSamples, 5000)\n",
        "w7 = np.random.rand(1, np.shape(x7)[1])\n",
        "t7 = generateTargetVector(x7, w7, bias, noise_variance)\n",
        "\n",
        "x8 = generateDataMatrix(NumberOfSamples, 7000)\n",
        "w8 = np.random.rand(1, np.shape(x8)[1])\n",
        "t8 = generateTargetVector(x8, w8, bias, noise_variance)\n",
        "\n",
        "x9 = generateDataMatrix(NumberOfSamples, 9000)\n",
        "w9 = np.random.rand(1, np.shape(x9)[1])\n",
        "t9 = generateTargetVector(x9, w9, bias, noise_variance)\n",
        "\n",
        "x10 = generateDataMatrix(NumberOfSamples, 9000)\n",
        "w10 = np.random.rand(1, np.shape(x10)[1])\n",
        "t10 = generateTargetVector(x10, w10, bias, noise_variance)\n",
        "\n",
        "\n",
        "time_vars = []\n",
        "\n",
        "start = time.time()\n",
        "w_t1, nrmse_t1 = estimateLRweights(x1, t1, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t2, nrmse_t2 = estimateLRweights(x2, t2, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t3, nrmse_t3 = estimateLRweights(x3, t3, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t4, nrmse_t4 = estimateLRweights(x4, t4, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t5, nrmse_t5 = estimateLRweights(x5, t5, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t6, nrmse_t6 = estimateLRweights(x6, t6, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t7, nrmse_t7 = estimateLRweights(x7, t7, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t8, nrmse_t8 = estimateLRweights(x8, t8, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t9, nrmse_t9 = estimateLRweights(x9, t9, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "start = time.time()\n",
        "w_t10, nrmse_t10 = estimateLRweights(x10, t10, eta, max_iter, epsilon, 0, 0)\n",
        "end = time.time()\n",
        "time_vars.append(end-start)\n",
        "\n",
        "\n",
        "time_vars = np.array(time_vars)\n",
        "n_vars = np.array([10, 100, 500, 1000, 2000, 4000, 5000, 7000, 9000, 10000]) # Google Colab crashes when I use n_vars = 100000\n",
        "\n",
        "plt.plot(n_vars, time_vars)\n",
        "plt.title(\"Time Taken for Gradient Descent v/s Number of Variables\")\n",
        "plt.xlabel(\"Number of Variables\")\n",
        "plt.ylabel(\"Time Taken for Gradient Descent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "fhSTEjqVpN6X",
        "outputId": "7d55983a-3b3e-4b15-bf8d-fabecf28d413"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f135168f80e9>:3: RuntimeWarning: overflow encountered in square\n",
            "  return np.sum(np.square(y-t)) / N\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "<ipython-input-13-f414cbac5874>:13: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  if abs(new_nrmse - old_nrmse) < min_change_NRMSE:\n",
            "<ipython-input-6-4c499d57129d>:4: RuntimeWarning: overflow encountered in multiply\n",
            "  MSEgradient = np.append(np.sum(2*(computeLRestimate(X, weights)-t))/N, 2*(X.T).dot(computeLRestimate(X, weights)-t)/N) # Appending the gradient of MSE wrt to the bias term to the gradient vector of MSE wrt to the weights vector\n",
            "<ipython-input-12-eecfbf53bf36>:3: RuntimeWarning: invalid value encountered in multiply\n",
            "  updated_weights = weights - eta*(computeMSEgradient(X, t, weights) + Lambda2*computeL2gradient(weights) + Lambda1*computeL1gradient(weights))\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Time Taken for Gradient Descent')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gd1bX38e9PkntvGFdcsAHjAljYpkPoYEIuAYJDIDSTkJBOLiE3IYRwk5DCm0ICAQMGLj0h9F5NAHewcW+yccOWLfemtt4/ZgsGWWUk6+hIR+vzPHp0Zk9bU85ZM3tm9sjMcM455+Ky0h2Ac865hseTg3POub14cnDOObcXTw7OOef24snBOefcXjw5OOec24snB+ecc3tp1MlB0lxJJ6Y7jopImijplnqYz39JWilpu6TDUz2/uiLpLUlXhc8XS3ol3TG59Kqv70wl85ak+yRtkjS1Hub3U0kTEg5b5XqRZJIOrLvoIg06OYQfvLK/Ukm7Yt0Xm9mhZvZWimO4MzbPQklFse4XUznvhP4AXGtmbc3sg7qYoKRTJb0paZukjZI+lHS9pJZ1Mf3yzOwhMzutLqZV3RdF0mWSSmLbMC/8KAyui/mngqTlkk7Zx2mMk/RwLea7XlKbWNlVkt7al1gaqGOBU4HeZjYq3kPSGEk7JLUtP5KkDyRdW9OZmdmvzeyq2oebeg06OYQfvLZm1hb4GDgnVvZQPcXwzVgMvwYei8VwZn3EUI0DgLm1GVFSdgVlFwD/BB4GDjCzLsBXgN5An0qmk1Ob+afR+2F7dgBOAXYBMyQNTW9YKXU28EItxssGvlfHsaRcRft2NQ4AlpvZjvI9zGwysAo4v9w8hgJDgEdqGFuj+L406ORQnfgRlaSbJD0h6f/CEe9HkgZLuiEc/ayUdFps3A6S7pG0VtJqSbfUdIcK8/tE0hZJkyQdWslw7cKR+F/C6evBkl6VVCBpoaQLY8NOlPQ3Sc+H5ZgiaWAF02whaTvRl3eWpKWh/JBQZbM5VLt9sdy075D0gqQdwEnlpingNuBmM7vbzAoAzGyhmX3HzBbH1vU/w7reClwmaZSk98N810q6XVLz2LRPlbQgrKvbAcX6XSbpP7HuWq0fSZPCYLPCWcFXqtp+ZlZiZkvN7FvA28BNsfmMkfReWJ5ZilVfhniXhfnnSbo41m+8pPmh3zxJR4TynpL+JSk/jPPd2Dg3SXpc0gNhvLmSckO/B4G+wLNhmf67/HKE+Y2NdeeE+ZTNO4voqPglSS3DdtsYlm2apO5VrKbfA9dJ6ljBfPspOlPLiZXFqwsvk/SupP8X5rVM0tGhfKWi7+XXy022a9j22yS9LemA2LSr2y8q3bdj2+CZMP4SSeND+ZXABOCosI5/WcF6uB+4tFzZpcALZrZR0p/DMm2VNEPScbH5VvR9uUnS/8WGqe63pNL1Um4ZW0j6g6SPJa1TVPPRKvTrKum5sC0KJL0T9o2KmVmj+AOWA6dUVkb0xd4NnA7kAA8AecD/AM2A8UBebNx/A/8A2gD7AVOBb1QTw03A/8W6rwDaAS2APwEfxvpNBG4BuoRp3xLK2wArgctDnIcDG4AhsfE2AqNC/4eAR6uIyYADw+dmwBLgp0Bz4AvANuCg2LS3AMcQHRi0LDetg8P0+iVYD0XAl8J0WgEjgTEh5n7AfOD7YfiuIY7zQ4w/AIqBq0L/y4D/1MX6ia+PSmL/dF7lyq8A1oXPvcI8zgrLd2ro7hbi2xpbpz2AQ8PnC4DVwJFEye9AoiPSLGAGcGPYLgOAZcDp5fbds4iS/W+AyVXt++VivxF4KNZ9NjA/1j2G6GwJ4BvAs0DrMK+RQPuqvnPAk3y2/14FvBU+9wvrOyc2zlvltmtx2JbZRN+Hj4G/EX1nTgv7RdvYtt0GHB/6/7mG+0Wl+3YYZhLwd6AlcBiQD3yhqv0iNm6fsCx9QncW0dnEl0L314i+6znAj4BPymKg4u/LTdTst6TC9VLBb8D/A54BOofpPQv8JvT7DXAn0XewGXAcoEqXeV9/tOvrj2TJ4dVYv3OA7UB26G4XVmJHoDuwB2gVG34c8GY1MXxug5br1zFMv0Nsg94LzAF+HBvuK8A75cb9B/CL2HgTYv3OAhZUEVN8xzgu7JRZsf6PADfFpv1AFdM6NkyvZazsUWAzsBO4JLYeJlWzrr4P/Dt8vpTP/9iJ6ItVUXLYp/VD7ZPDGUBR+Hw98GC5/i8DXyf6kdoMfDm+/8SG+V4F0x4NfFyu7Abgvtj6fC3Wbwiwq6p9v9y0DiT68Wgduh8Cboz1/xXw8/D5CuA9YHjS7xwwlOiHtxs1Tw6LY/2GheG7x8o2AofFtm080bcFSoh+mJPsF1Xt233CtNrFyn4DTKxqvyg3jdeAn4bPpxIll2aVDLsJGFHZ94Wa/5ZUuF7i+zzR92oHMDA27FGEg2LgZuBpqvh+xP8adbVSBdbFPu8CNphZSawbohV7AFHmXBtOsTYT7Wj7JZ2RpGxJv5W0NJwqLg+9usYGO5voKOHOWNkBwOiy+YZ5XwzsHxvmk9jnnSHmJHoCK82sNFa2guhIuMzKKsbfGP73KCsws4vMrCMwk+jor8LpKKrCey6cGm8luj5Tti56xoe3aE+tLI5Urp+q9AIKYjFcUC6GY4EeFtVJfwX4JtH+87ykg8N4fYCllSxTz3LT+ynRQUply9RSCeumzWwJ0ZnaOZJaA18kumZU5iw+u97wIFESe1TSGkm/k9SsmunPAZ4DfpIknnLKfycxs/Jl8e0X30+2E22TniTbL6rat3sCBWa2LVZW/rtRnfuBS8LnS4h+sIsAJF0Xqve2hNg68PnfgkpjS/hbUtl6ietGdEY4I7aOXgrlEFURLgFeCVV8VW7PRnFhJAVWEp05dDWz4lpO46vAuURHVsuJdoZNxOrSgbuBTsALks4IPywrgbfN7NRazrcqa4A+krJiCaIvsCg2jFUx/kKiapHzgD9WM6/y07kD+AAYZ2bbJH2fzy7grSV2MVuSqOTiNqldP1X5L+CdWAwPmtn4igY0s5eBl0Nd7i1E2/m4MN5e14dCeZ6ZDaplbFVtszKPEJ39ZgHzQsJA0v5EyX5miL0I+CXwS0n9iJLGQuCeaqb/izCN+H5RdvG2NVFVG3z+x7o24vtJW6LqkTUk2y+qWk9rgM6S2sUSRF+i/T2pJ4G/SzqJ6DtyYojzOOC/gZOBuWZWKqn8b0FVsSX5LalsvcRtIEq2h5rZXssVlvtHwI8UXUx/Q9I0M3u9oqAy7cwhETNbC7wC/FFSe0lZkgZKOqEGk2lHlGA2En05fl3JcNcSffmeDT8mzwGDJV0iqVn4O1LSIbVfok9NITrq/O8w3ROJqtceTTJySCg/An6h6MJqJ0UG8fmj3Iq0I/qB2B6OpK+J9XseOFTSeeFo+LtU/iOyr+tnHVGdfrXCEVt/SX8l+qKXXYj8P6Kj8NPDMC0lnSipt6Tuks5VdHvnHqKqy7JEPIHo4u3IsN4ODBcOpwLbFN0O3CpMc6ikI+twmR4lqsO/hs+fNZwJvBTO1pB0kqRhim6+2EpUF15afmLlhWTzGNG2KyvLJ/px/VpYpiuoODnWxFmSjlV0M8OviKojV7KP+0WYxnvAb8L2HA5cSbStEwkHd/8E7gNWmNn00Ksd0fWIfCBH0o1A+6TTJdlvSWXrJR5fKdGByv+TtB+ApF6STg+fx4Z9UkTVhCVUse2bZHIILiW6ODiPKEv/k1h1SgIPEJ2Wrg7TmFzRQOFLeTVRHfvTRF/G04CLiDL/J8CtRBea9omZFRIlgzOJjiL+DlxqZgtqMI3HgAuJLrCtDNN5HLgLeKKKUa8jOgLaRrSDPhab5gaii7W/JfoCDALerWT+29i39XMTcH84rb6wkmGOUnSn11aiOvL2wJFm9lGIYSXRkdxPib7wK4EfE31fsoAfhtgKgBMIidDMngD+l+jHeRvwFNA5VG2OJboImke0TicQHSEm8RvgZ2GZrqtogHDA8z5wNLF1z963sO5PtK9vJaqKepuoqimJm4muucSNJ1o3G4FDiX6A98XDRGcpBUQXy78GdbJfQHRm1S+M/2+i6xWv1TC++4mquB6Ilb1MVH2ziOg3YTdVV3GVl+S3pML1UoHriaqOJocqqteAg0K/QaF7O9G+8ncze7OyoBQOKJxzGSacpX0CDDCzrdUN71xcUz5zcC7TdSa6S8kTg6uxlCUHSfcqeshlTiX9O0h6VtEDRnMlXZ6qWJxrisxsvZndke44XOOUyjOHiUT3jlfm20R3VYwguhj4R8WeqHXOOZc+KbuV1cwmhVvlKh0EaBeunLclutBS7W2lXbt2tX79qpqsc8658mbMmLHBzLpVP2Qknc853E70mPcaolu5vlLu4a0K9evXj+nTp1c3mHPOuRhJK2oyfDovSJ8OfEj0lN9hwO2SKrw3WNLVkqZLmp6fn1+fMTrnXJOUzuRwOfCkRZYQ3f99cEUDmtldZpZrZrnduiU+K3LOOVdL6UwOHxM9bo6iJoMPImqp0jnnXJql7JqDpEeI7kLqKmkV0dN9zQDM7E6iR8AnSvqIqA2R68OTtM4559IslXcrjaum/xqix+Gdc841MP6EtHPOub14cnDOObeXpvo+B+ecq5Gtu4t4f+lGVmzcweF9OzGid0ea52Tu8bUnB+ecq0BJqfHR6i28syifSYvzmfnxZkpKP2vFumWzLHIP6MyYAZ05amAXhvXKrGThycE554K1W3bxzqINvL04n3eXbGDzziIAhvXqwDeOH8Dxg7sxoFsbZq7YzORlG5m8bCN/eCV60WKrZtnk9uvEmAFdQrLoQLPsxpssGt37HHJzc82bz3DO1YXdRSVMyStg0qJ8Ji3KZ/H67QDs164Fxw3qxvGDu3LsgV3p0rbydwoV7ChkSkgU7y/byKJ10TTaNM8mt1/nT5PF0J7tyUljspA0w8xyEw/vycE511SYGQvXbWPSonzeWbyBKXkFFBaX0jwni1H9OnP84K4cP7gbB3VvR9QmaM1t2L6HKcsKPk0WS0LCadsihyNjZxaH9uxAdlbt5lEbnhyccy6mYEch7yzOZ9KiDbyzOJ/12/YAMGi/thw/uBvHDerK6P5daNU8OyXzz9+259MqqPeXbWRZ/g4A2rXIYVT/z84sDunRPqXJoqbJwa85OOcySmFxKR98vIlJISHMWbMFM+jQqhnHDurKCYO6ceygrvTs2Kpe4unWrgXnjOjJOSN6ArB+627eX7aRyeHs4vUF6wFo3zKHUf27fHqB+5D925NVj2cW5fmZg3Ou0Vu+YQfvLM7n7UUbeH/pBnYUlpCdJY7o2zFcO+jGsF71W42T1Cdbdn/uzGLFxp1AlMxGx84sDurebp+ShVcrOecy3rbdRby3dOOn1w4+Loh+UPt0bsXxg7px3KBuHH1gF9q3bJbmSGtuzeZdUaJYupHJeRtZWbALgE6tm/Htkw7kquMG1Gq6Xq3knMs4JaXGnNVboruKYs8ctGmezVEDu3DVcf05blA3+nVpXesLyQ1Fz46tOO+I3px3RG8AVm3ayeRlBby/dCP7tW9Zb3H4mYNzrkEqe+Zg0uJ8/lPumYPjBkV3FR3Rt1NGPXiWSn7m4JxrlOLPHLyzOP/T5wX2a9eCkw/unuiZA1d3PDk459LCzFi0bvunVUXlnzk4f2TvfX7mwNWeJwfnXL0pe+bgncXRMwfrtn72zMElYw5I+TMHLjlPDs65lCkqKWXmiuiZg3cWb+Cj1el95sAl58nBOVenqnrm4AenDG7Qzxy4z3hycM7tk7JnDsqaqIg/c/Clw3s16mcOmjJPDs65Wpm7Zgu/fHYeM1dsojhDnzloylKWHCTdC4wF1pvZ0EqGORH4E9AM2GBmJ6QqHudc3VnwyVa+NmEKzXOyuDq858CfOcgsqTxzmAjcDjxQUU9JHYG/A2eY2ceS9kthLM65OrJk/fZPE8Pj3ziKA7q0SXdILgWqTfOSLkhSVp6ZTQIKqhjkq8CTZvZxGH59ddN0zqXXio07uHjCZEA8PH6MJ4YMluQc8IaEZTU1GOgk6S1JMyRdWtmAkq6WNF3S9Pz8/DqYtXOuplZt2slX755CYXEpD101moHd2qY7JJdClVYrSToTOAvoJekvsV7tgeI6mvdI4GSgFfC+pMlmtqj8gGZ2F3AXRG0r1cG8nXM18MmW3Vw8YQrbdhfx8PgxHLR/u3SH5FKsqmsOa4DpwBeBGbHybcAP6mDeq4CNZrYD2CFpEjAC2Cs5OOfSJ3/bHi6eMJmN2wt58MpRDO3VId0huXpQaXIws1nALEkPm1lRCub9NHC7pBygOTAa+H8pmI9zrpY27SjkknumsGbzbu6/YhSH9+2U7pBcPUlyt9IoSTcBB4ThBZiZVfnGCUmPACcCXSWtAn5BdMsqZnanmc2X9BIwGygFJpjZnNouiHOubm3ZVcQl905h2YYd3HfZkYzq3zndIbl6lCQ53ENUjTQDKEk6YTMbl2CY3wO/TzpN51z92L6nmMvum8rCT7Zx16W5HHNg13SH5OpZkuSwxcxeTHkkzrkGYVdhCVdMnMbsVVv4+8VHcNJB/ghSU5QkObwp6ffAk8CeskIzm5myqJxzabG7qITxD0xn+vIC/nzR4Zx+6P7pDsmlSZLkMDr8j79ezoAv1H04zrl0KSwu5VsPzeQ/SzbwhwtGcM6InukOyaVRtcnBzE6qj0Ccc+lTXFLKdx/5gDcWrOfX/zWM80f2TndILs2SNJ/RXdI9kl4M3UMkXZn60Jxz9aGk1Pjh47N4ae4n/OKcIXx1dN90h+QagCTNZ0wEXgbKzjEXAd9PVUDOufpTWmpc/6/ZPDNrDdefcTCXH9M/3SG5BiJJcuhqZo8TPYuAmRVTg1tanXMNk5nx86fn8M8Zq/j+KYO45sSB6Q7JNSBJksMOSV2ILkIjaQywJaVROedSysz41XPzeWjKx3zzhIF87+RB6Q7JNTBJ7lb6IfAMMFDSu0A34PyURuWcSxkz4/cvL+Ted/O4/Jh+XH/GQf7GNreXJHcrzZR0AnAQUdMZC1PU1pJzrh789Y0l/P2tpXx1dF9uHDvEE4OrUJK7lb4NtDWzuaHto7aSvpX60Jxzde0fby/ltlcX8eUjenPLuUM9MbhKJbnmMN7MNpd1mNkmYHzqQnLOpcLEd/P4zYsLOGdET353/nCysjwxuMolSQ7Zih1eSMomamLbOddIPDzlY256dh6nH9qd2y4cQbYnBleNJBekXwIek/SP0P2NUOacawSenLmK/3nqI046qBt/GXc4zbKTHBO6pi5JcrgeuBq4JnS/CkxIWUTOuTrz3Ow1XPfELI4e2IU7vjaSFjnZ6Q7JNRJJ7lYqBe4E7pTUGehtZv4QnHMN3CtzP+F7j35I7gGdufvSXFo288Tgkktyt9JbktqHxDADuFuSv87TuQbszYXr+fbDMxnWqwP3XJZL6+ZJKgmc+0ySyscOZrYVOA94wMxGAyenNiznXG29t2QD33xwBoO7t+P+K0bRrmWzdIfkGqEkySFHUg/gQuC5FMfjnNsH05YXcOX90+nXpQ0PXjmaDq08MbjaSZIcbiZqlXWpmU2TNABYXN1Iku6VtF7SnGqGO1JSsSRvksO5ffDhys1cft80enRsyf9dNZrObfyOc1d71SYHM3vCzIab2TWhe5mZfTnBtCcCZ1Q1QHhm4lbglQTTc85VYs7qLVx6zxQ6t2nOw1eNoVu7FukOyTVySS5ID5b0etkZgKThkn5W3XhmNgkoqGaw7wD/AtYnCdY5t7dF67ZxyT1TaNeyGQ+PH83+HVqmOySXAZJUK90N3AAUAZjZbOCifZ2xpF7AfwF3JBj2aknTJU3Pz8/f11k7lzGW5W/nq3dPoVl2Fg9dNZrenVqnOySXIZIkh9ZmNrVcWXEdzPtPwPXhOYoqmdldZpZrZrndunWrg1k71/h9vHEnX717CmbGw+NH069rm3SH5DJIkpufN0gayGcv+zkfWFsH884FHg3NNnUFzpJUbGZP1cG0nctoqzfv4qsTJrO7uIRHxo/hwP3apTskl2GSJIdvA3cBB0taDeQBF+/rjM3s05fVSpoIPOeJwbnqrdu6m4vvnsyWXUU8fNUYDunRPt0huQyUpPmMZcApktoAWWa2LcmEJT0CnAh0lbQK+AXQLEzzzlpH7FwTtmH7Hi6eMIX8bXt44MrRDOvdId0huQxVZXKQdBBRo3sHh6L5ku4ys0XVTdjMxiUNwswuSzqsc03V5p2FfG3CFFZt2sn9l49i5AGd0h2Sy2CVXpCWdBTwFrCNqFrpbmAH8JakMfUSnXMOgK27i7jknqks27CDuy/NZfSALukOyWW4qs4cbgTGmdlbsbKnJL1BVEV0ZioDc85Ftu8p5rJ7p7Lgk63c+bWRHDfI79hzqVfVrawDyyUGAMzsbWBAyiJyzn1qV2EJV06cxqxVW/jruMM5+ZDu6Q7JNRFVJYeqLjzvqOtAnHOft7uohKsfnM7U5QXcduEIzhjaI90huSakqmqlPpL+UkG5gF4pisc5BxQWl3LtwzN5Z/EGfnf+cM49zL9yrn5VlRx+XEW/6XUdiHMuUlxSyvce/YDX5q/nV18ayoW5fdIdkmuCKk0OZnZ/fQbinIOSUuO6J2bx4pxP+NnZh3DJmAPSHZJropK0reScqwelpcZPn/yIpz5cw49PP4irjvP7Plz6eHJwrgEwM37xzFwem76S737hQL590oHpDsk1cUne53BMkjLnXO2YGf/7/HwenLyCbxw/gB+cOjjdITmX6MzhrwnLnHO18MdXFjHhP3lcdnQ/fnLmwYSWip1Lq0ovSIfmM44Gukn6YaxXeyA71YE51xTc/sZibn9zCeNG9eHGsUM8MbgGo6pbWZsDbcMw8cbitwLnpzIo55qCuyct4w+vLOK8w3vxv18aRlaWJwbXcFR1K+vbwNuSJprZinqMybmM98D7y/nfF+Zz9rAe/O784Z4YXIOT5GU/LSTdBfSLD29mX0hVUM5lssemfcyNT8/l1CHd+dNFh5GT7TcNuoYnSXJ4ArgTmACUpDYc5zLbvz9YxU+e/IgTBnfj9q8eTjNPDK6BSpIcis3sjpRH4lyGe+Gjtfzo8VmM6d+Ff1wykhY5fl+Ha7iSHLY8K+lbknpI6lz2l/LInMsgr81bx3cf+YAj+nZiwtdzadnME4Nr2JKcOXw9/I83xGf4Ox2cS+TtRfl866GZHNqzPfddfiRtWiT52jmXXtXupWbWvzYTlnQvMBZYb2ZDK+h/MXA9URPg24BrzGxWbeblXEP1/tKNXP3AdA7cry0PXDGadi2bpTsk5xJJ0nxGa0k/C3csIWmQpLEJpj0ROKOK/nnACWY2DPgV0XuqncsYM1YUcOX90+jbuTUPXjmKDq09MbjGI8k1h/uAQqKnpQFWA7dUN5KZTQIKquj/npltCp2Tgd4JYnGuUZi9ajOX3TuN7u1b8tD40XRp2yLdITlXI0mSw0Az+x1QBGBmO4mqgurSlcCLlfWUdLWk6ZKm5+fn1/Gsnatb89Zs5ZJ7ptKxTTMeHj+a/dq1THdIztVYkitjhZJaEV2ERtJAYE9dBSDpJKLkcGxlw5jZXYRqp9zcXKurebvM8+HKzSz8ZCvtWjajXcuc2P8c2rVoRstmWSltv2jxum187Z4ptG6ezcNXjaFHh1Ypm5dzqZQkOfwCeInondIPAccAl9XFzCUNJ3q47kwz21gX03RN067CEn738gLue3d5lcPlZGnvpFH2uUVOxUml3Oc2zbMrTDB5G3bw1QlTyM4SD48fQ5/OrVO0tM6lXpK7lV6VNBMYQ1Sd9D0z27CvM5bUF3gSuMTMFu3r9FzT9cHHm/jR47NYtmEHlx3dj8uP6ceuohK27S5m2+4itu0uZmvs8/bY5227i1lZsPPTYbfvKaa0mnPTLEHbWCJp37IZbVvmMGf1FkpKjceuHkP/rm3qZ+GdS5Gqmuw+2MwWSDoiFK0N//tK6mtmM6uasKRHgBOBrpJWEZ2BNAMwszuBG4EuwN/DUVixmeXuy8K4pqWwuJQ/v76IO95ayv7tW/LQVaM55sCu+zRNM2Nn4WeJZWu5RLJ9z2eft35aXsS6rbvp0bEVv/mvYQzq3q76GTnXwMms4sMkSXeb2XhJb1bQ29LV8F5ubq5Nnz49HbN2Dcj8tVv5wWMfsuCTbVwwsjc/P2cI7f0ZAucqJWlGTQ7Aq2qye3z4f1JdBOZcXSguKeUfk5bxp9cW0aFVcyZcmsspQ7qnOyznMk5V1UrnVTWimT1Z9+E4V7ll+dv50ROz+ODjzZw9rAe/+tJQOrdpnu6wnMtIVV2QPif834/oAbg3QvdJwHtEF5OdS7nSUuP+95dz60sLaJGTzV/GHc4XR/RMd1jOZbSqqpUuB5D0CjDEzNaG7h5ETWM4l3KrNu3kx0/M5v1lGznpoG789svD6d7eHypzLtWSPOfQpywxBOuAvimKxzkgumvoiemruPm5eZgZvz1vGF85sk9KH2Bzzn0mSXJ4XdLLwCOh+yvAa6kLyTV167fu5oYnP+L1BesZM6Azvz9/hD9Q5lw9S/IQ3LXh4vRxoeguM/t3asNyTdVzs9fws6fmsKuwhBvHDuGyo/uRleVnC87Vt0RvHQl3JvkFaJcym3YU8vOn5/Dc7LWM6NORP14wggP3a5vusJxrsqpNDpLGAH8FDgGaA9nADjNrn+LYXBPxxoJ1XP+vj9i8s5DrThvMN08YSE52kgaDnXOpkuTM4XbgIuAJIBe4FBicyqBc07BtdxG3PDefx6av5OD92zHx8iM5tGeHdIflnCN5tdISSdlmVgLcJ+kD4IbUhuYy2XtLN/DjJ2azdssuvnXiQL53yiBa5GSnOyznXJAkOeyU1Bz4UNLviBrg83N+VyvxprX7d23DE988mpEHdEp3WM65cpIkh0uIksG1wA+APsCXUxmUy0zlm9a+/oyDadXczxaca4iqTA6SsoFfm9nFwG7gl/USlcso8aa1e3RoxcNXjebofWxa2zmXWlUmBzMrkXSApOZmVlhfQbnM4U1rO9c4JalWWga8K+kZYEdZoZndlrKoXKPnTWs717glSQ5Lw18W4A6OfJ4AABjYSURBVK+4ctX6XNPaw3twy7lD6eRNazvXqCRpPsOvM7hE4k1rt2yWzV/HHc453rS2c41SVS/7ORYYYGYPhO5/Ap1D71vM7I3KxnVNT/mmtW/98nD286a1nWu0qjpz+CXwnVj3QcBlQBvgp3z28p8KSboXGAusN7OhFfQX8GfgLGAncJmZzaxJ8C79yjetfeuXh3Fhrjet7VxjV1VyaG9m82Ldi81sBoCk3ySY9kSipjceqKT/mcCg8DcauCP8d42EN63tXOaqKjl0jHeYWfyd0tXedmJmkyT1q2KQc4EHzMyAyZI6SupR7sVCroHyprWdy2xVJYcFks42s+fjhZLGAgvrYN69gJWx7lWhbK/kIOlq4GqAvn39JXTpVL5p7dsuHMHAbt60tnOZpqrk8APgeUnnA2XXAkYCRxNdS6g3ZnYXcBdAbm6u1ee83WfiTWv/+PSD+MbxA7xpbecyVKXJIbTEOhy4GDg0FE8Cvmlmu+tg3quJ2mkq0zuUuQZm2+4ifvXcPB6fvoqD92/H/ZePYkhPf52Hc5msuuYz9gD3pmjezwDXSnqU6EL0Fr/e0PB409rONU2J3udQG5IeAU4EukpaBfwCaAZgZncCLxDdxrqE6FbWy1MVi6u5XYUl3PrSAia+FzWt/c9rjuaIvt60tnNNRcqSg5mNq6a/Ad9O1fxd7c38eBPXedPazjVpSZrsfiA02e0ynDet7Zwr4012OwDmrdnKDx+Pmta+MLc3PxvrTWs715R5k91NnDet7ZyriDfZ3YQtzd/Ojx6fxYcrvWlt59znJW6yW1Lb0L091UG51PKmtZ1z1ak2OUgaCjxIaK5b0gbgUjObm+LYXArEm9b+wsH78dvzhnnT2s65vSSpVroL+KGZvQkg6UTgbqJmNFwjYWY8Pn0lv3puvjet7ZyrVpLk0KYsMQCY2VuS2qQwJlfHvGlt51xNJbpbSdLPiaqWAL5GdAeTawSenbWGnz8dNa39i3OG8PWjvGlt51z1kiSHK4jeCvckYMA7ocw1UJt2FPLy3E94+sM1vL9sI4f16cgfvWlt51wNVPUO6QfN7BKii8/frceYXC1s2VnEy/M+4bnZa3l3yQZKSo1+XVrz07MO5opj+nvT2s65GqnqzGGkpJ7AFZIeAD5XF2FmBSmNzFVr6+4iXp27judmr+E/SzZQVGL07dyaq48fwNnDenBoz/Z+wdk5VytVJYc7gdeBAcAMPp8cLJS7erZtdxGvzV/H87PXMmnRBgpLSunVsRVXHNOfs4f3YFivDp4QnHP7rKqX/fwF+IukO8zsmnqMyZWzY0/xpwnhrUX5FBaX0qNDSy496gDOHt6Dw/p09ITgnKtTSZ6Q9sSQBjsLi3ljwXqen72WNxasZ09xKd3bt+Di0X0ZO7wnh/fp6HcdOedSJmXvc3A1t6uwhLcWrue5j9byxvz17CoqoVu7Flx0ZB/GjujJyL6dPCE45+qFJ4c0211UwtuL8nl+9lpem7+OnYUldGnTnC+P7MXY4T05sl9nsj0hOOfqmSeHNNhTXMI7izbw/EdreXXeOrbvKaZT62ace1gvzhneg1H9O/utp865tErS8N55wK3AfkR3LInoLZ/tUxxbRiksLuXdJRt4dvYaXp27jm17iunQqhlnD+vB2BE9GDOgC808ITjnGogkZw6/A84xs/k1nbikM4A/A9nABDP7bbn+fYH7gY5hmJ+Y2Qs1nU9DVlRSyi3PzePfH6xm6+5i2rXM4fSh+zN2eA+OObCrJwTnXIOUJDmsq2ViyAb+BpwKrAKmSXrGzObFBvsZ8LiZ3SFpCPAC0K+m82rI3lu6kfvfX8EZh+7PhUf25tgDu9E8xxOCc65hS5Icpkt6DHgK2FNWaGZPVjPeKGCJmS0DkPQocC4QTw4GlFVPdQDWJIy70Ziat5GcLHHbV0bQurlf4nHONQ5Jfq3aAzuB02JlRtQQX1V6AStj3auA0eWGuQl4RdJ3gDbAKRVNSNLVwNUAffv2TRBywzE1r4ChvTp4YnDONSpJHoK7PIXzHwdMNLM/SjoKeFDSUDMrLRfDXUQvHSI3N9dSGE+d2l1UwqyVW7j8mH7pDsU552qk2spvSYMlvS5pTugeLulnCaa9GugT6+4dyuKuBB4HMLP3gZZA1ySBNwazVm6msKSUI/t1TncozjlXI0mujN4N3AAUAZjZbOCiBONNAwZJ6i+peRjnmXLDfAycDCDpEKLkkJ8s9IZval4BEp4cnHONTpLk0NrMppYrK65uJDMrBq4FXgbmE92VNFfSzZK+GAb7ETBe0izgEeAyM2s01UbVmbq8gIO6t6ND62bpDsU552okyVXSDZIGEl2ERtL5wNokEw/PLLxQruzG2Od5wDGJo21EiktKmbFiExeM7J3uUJxzrsaSJIdvE10MPljSaiAPuDilUWWAuWu2srOwhFH9u6Q7FOecq7EkyaGTmZ0iqQ2QZWbbJI0FVqQ4tkZtal70orwj+3dKcyTOOVdziS5Ih9tLd4TEcBHw81QH1thNySugf9c27NeuZbpDcc65GkuSHM4HHpB0sKTxRNVMp1UzTpNWWmpMW17AKL9LyTnXSCV5CG5ZOFt4iujW09PMbFfKI2vEFq3fxpZdRYzq78nBOdc4VZocJH1EuEMp6EzUcuoUSZjZ8FQH11hNC9cbPDk45xqrqs4cxtZbFBlmSl4BPTq0pHenVukOxTnnaqXS5GBmn7sbSdJ+RE8wuyqYGVPzCjhqYBckf72nc65xStK20hclLSZ6vuFtYDnwYorjarRWbNzJ+m17vErJOdeoJblb6VfAGGCRmfUnagtpckqjasTKnm8Y7cnBOdeIJUkORWa2EciSlGVmbwK5KY6r0Zq6vIDObZozsFvbdIfinHO1VmlykHRt+LhZUltgEvCQpD8DO+ojuMZoal4BR/br5NcbnHONWlVnDleE/+cCu4AfAC8BS4FzUhxXo7R2yy4+Ltjp7Sk55xq9JA/Bxc8S7k9hLI2eX29wzmWKqpLDcElbKygXYGbWPkUxNVpT8wpo2yKHQ3r4qnHONW5VJYePzOzweoskA0xbXkBuv05kZ/n1Budc45bkbiWXQMGOQhat2+6vBHXOZYSqksMT9RZFBpi23K83OOcyR6XJwcx+XZ+BNHZT8wpokZPFsN4d0h2Kc87ts5RWK0k6Q9JCSUsk/aSSYS6UNE/SXEkPpzKeVJqaV8DhfTvSIic73aE459w+S1lykJQN/A04ExgCjJM0pNwwg4AbgGPM7FDg+6mKJ5W27ylm7pot/nyDcy5jJGl4r7ukeyS9GLqHSLoywbRHAUvMbJmZFQKPEj1QFzce+JuZbQIws/U1C79hmLFiE6WGv/nNOZcxkpw5TAReBnqG7kUkO8LvBayMda8KZXGDgcGS3pU0WdIZFU1I0tWSpkuanp+fn2DW9Wtq3kZyssQRB3RMdyjOOVcnkiSHrmb2OFAKYGbFQEkdzT8HGAScCIwD7pa01y+smd1lZrlmltutW7c6mnXdmZpXwNBeHWjdvNoHzp1zrlFIkhx2SOpCeGWopDHAlgTjrQb6xLp7h7K4VcAzZlZkZnlEZyWDEky7wdhdVMKslVv8FlbnXEZJkhx+CDwDDJT0LvAA8J0E400DBknqL6k5cFGYTtxTRGcNSOpKVM20LFnoDcOslZspLCn1l/s45zJKkob3Zko6ATiIqF2lhWZWlGC84tDs98tANnCvmc2VdDMw3cyeCf1OkzSPqKrqx+HdEY3G1LwCJMg9wJODcy5zVJscwi2pZwH9wvCnScLMbqtuXDN7AXihXNmNsc9GdGbyw5qF3XBMXV7AQd3b0aF1s3SH4pxzdSbJFdRngd3AR4SL0i5SVFLKjBWbuGBk73SH4pxzdSpJcuhtZsNTHkkjNHfNVnYWlvjDb865jJPkgvSLkk5LeSSN0LTwcp8j+3dKcyTOOVe3kpw5TAb+LSkLKMJf9vOpKXkF9O/ahv3atUx3KM45V6eSnDncBhwFtDaz9mbWzhMDlJYa05YXeJMZzrmMlCQ5rATmhDuLXLBo/Ta27Cry5xuccxkpSbXSMuCt0PDenrLCJLeyZrKp4XqDJwfnXCZKkhzywl/z8OeIrjf07NCS3p1apTsU55yrc0mekP5lfQTSmJgZ0/IKOGpgFySlOxznnKtzlSYHSbeb2bWSniU0uhdnZl9MaWQN2IqNO1m/bY9XKTnnMlZVZw6XAtcCf6inWBqNsusN3hKrcy5TVZUclgKY2dv1FEujMSWvgM5tmjOwW9t0h+KccylRVXLoJqnSBvGa8t1KU5dvZFS/zn69wTmXsap6ziEbaAu0q+SvSVq7ZRcrC3b59QbnXEar6sxhrZndXG+RNBL+fINzrimo6szB60wqMDWvgLYtcjikR5NvQcQ5l8GqSg4n11sUjcjUvAJy+3UiO8tzp3Muc1WaHMysoD4DaQwKdhSyeP12r1JyzmW8JA3vuWDacn++wTnXNKQ0OUg6Q9JCSUsk/aSK4b4sySTlpjKefTU1r4AWOVkM69Ux3aE451xKpSw5SMoG/gacCQwBxkkaUsFw7YDvAVNSFUtdmZpXwOF9O9I8x0+4nHOZLZW/cqOAJWa2zMwKgUeBcysY7lfArcDuFMayz7btLmLumi3+vmjnXJOQyuTQi+hFQWVWhbJPSToC6GNmz1c1IUlXS5ouaXp+fn6tgnl/6UYuuPM9tuwqqtX4M1ZsotT8eoNzrmlIW/1IeCf1bcCPqhvWzO4ys1wzy+3WrVut5tc8R0xbvom3Fq6v1fjTlheQkyUO7+vXG5xzmS+VyWE10CfW3TuUlWkHDCV6y9xyYAzwTKouSh/WpxNd2zbn1XnrajX+1LwChvbqQOvmSd6P5JxzjVsqk8M0YJCk/pKaAxcBz5T1NLMtZtbVzPqZWT9gMvBFM5ueimCys8TJB3fn7YX5FBaX1mjc3UUlzFq5xauUnHNNRsqSg5kVE70P4mVgPvC4mc2VdLOktLwo6NQh3dm2p5jJyzYmHsfMeHHOWgpLSv3hN+dck5HSOhIzewF4oVzZjZUMe2IqYwE4dlBXWjXL5tV56zh+cNXXLtZv3c2/Zq7miekrWbZhB93bt+BITw7OuSaiSVWgt2yWzXGDuvLa/HXcfO6he72PobC4lDcWrOeJ6St5a1E+JaXGqH6duebEgZw1rAdtWjSp1eWca8Ka3K/dqUO688q8dcxZvZVhvTsAsGjdNh6ftpJ/f7CajTsK2a9dC75x/ADOH9mbAf62N+dcE9TkksPJh3QnS/DvD1Yze/VmHp++ilkrN9MsW5xySHcuyO3N8YO6kZPtT0E755quJpccOrdpTm6/ztz7bh4AB3Vvx8/HDuFLh/WkS9sWaY7OOecahiaXHAB+eOpgXpu3jnNG9GR47w7+LmjnnCunSSaHMQO6MGaAt5HknHOV8Yp155xze/Hk4Jxzbi+eHJxzzu3Fk4Nzzrm9eHJwzjm3F08Ozjnn9uLJwTnn3F48OTjnnNuLzCzdMdSIpHxgRS1H7wpsqMNwGgNf5qbBl7lp2JdlPsDMEr9nudElh30habqZpeQ1pA2VL3PT4MvcNNTnMnu1knPOub14cnDOObeXppYc7kp3AGngy9w0+DI3DfW2zE3qmoNzzrlkmtqZg3POuQQ8OTjnnNtLk0kOks6QtFDSEkk/SXc8tSWpj6Q3Jc2TNFfS90J5Z0mvSloc/ncK5ZL0l7DcsyUdEZvW18PwiyV9PV3LlJSkbEkfSHoudPeXNCUs22OSmofyFqF7SejfLzaNG0L5Qkmnp2dJkpHUUdI/JS2QNF/SUZm+nSX9IOzXcyQ9Iqllpm1nSfdKWi9pTqyszrarpJGSPgrj/EW1fdWlmWX8H5ANLAUGAM2BWcCQdMdVy2XpARwRPrcDFgFDgN8BPwnlPwFuDZ/PAl4EBIwBpoTyzsCy8L9T+Nwp3ctXzbL/EHgYeC50Pw5cFD7fCVwTPn8LuDN8vgh4LHweErZ9C6B/2Cey071cVSzv/cBV4XNzoGMmb2egF5AHtIpt38sybTsDxwNHAHNiZXW2XYGpYViFcc+sVZzpXlH1tDGOAl6Odd8A3JDuuOpo2Z4GTgUWAj1CWQ9gYfj8D2BcbPiFof844B+x8s8N19D+gN7A68AXgOfCjr8ByCm/jYGXgaPC55wwnMpv9/hwDe0P6BB+KFWuPGO3c0gOK8MPXk7Yzqdn4nYG+pVLDnWyXUO/BbHyzw1Xk7+mUq1UttOVWRXKGrVwGn04MAXobmZrQ69PgO7hc2XL3tjWyZ+A/wZKQ3cXYLOZFYfuePyfLlvovyUM35iWuT+QD9wXqtImSGpDBm9nM1sN/AH4GFhLtN1mkNnbuUxdbdde4XP58hprKskh40hqC/wL+L6ZbY33s+iQIWPuUZY0FlhvZjPSHUs9yiGqerjDzA4HdhBVN3wqA7dzJ+BcosTYE2gDnJHWoNKgoWzXppIcVgN9Yt29Q1mjJKkZUWJ4yMyeDMXrJPUI/XsA60N5ZcvemNbJMcAXJS0HHiWqWvoz0FFSThgmHv+nyxb6dwA20riWeRWwysymhO5/EiWLTN7OpwB5ZpZvZkXAk0TbPpO3c5m62q6rw+fy5TXWVJLDNGBQuOuhOdHFq2fSHFOthDsP7gHmm9ltsV7PAGV3LHyd6FpEWfml4a6HMcCWcPr6MnCapE7hiO20UNbgmNkNZtbbzPoRbbs3zOxi4E3g/DBY+WUuWxfnh+EtlF8U7nLpDwwiunjX4JjZJ8BKSQeFopOBeWTwdiaqThojqXXYz8uWOWO3c0ydbNfQb6ukMWEdXhqbVs2k+8JMPV4AOovozp6lwP+kO559WI5jiU45ZwMfhr+ziOpaXwcWA68BncPwAv4WlvsjIDc2rSuAJeHv8nQvW8LlP5HP7lYaQPSlXwI8AbQI5S1D95LQf0Bs/P8J62IhtbyLox6X9TBgetjWTxHdlZLR2xn4JbAAmAM8SHTHUUZtZ+ARomsqRURniFfW5XYFcsP6WwrcTrmbGpL+efMZzjnn9tJUqpWcc87VgCcH55xze/Hk4Jxzbi+eHJxzzu3Fk4Nzzrm9eHJwDYIkk/THWPd1km6qo2lPlHR+9UPu83wuCK2nvlmufFnseYWysj9Jur4G054gaUg1wyyX1LWC8pskXZd0Xs6BJwfXcOwBzqvoxy2dYk/mJnElMN7MTipX/ijRw3tl08wiemjr0YQxZJvZVWY2rwaxOLdPPDm4hqKY6P24Pyjfo/yRv6Tt4f+Jkt6W9HQ4Ov+tpIslTQ3t2Q+MTeYUSdMlLQptNZW9H+L3kqaFtvK/EZvuO5KeIXpCt3w848L050i6NZTdSPSA4j2Sfl9ulEeAr8S6jwdWmNkKSU9JmqHoHQZXx5dR0h8lzQKOkvSWpNzQ746wLHMl/bLcvP47xDZV0oEVxD5Q0kthnu9IOjiUXxCWZ5akSeXHc01PTY6KnEu1vwGzJf2uBuOMAA4BCojatJ9gZqMUvQTpO8D3w3D9gFHAQODN8MN5KVFzBEdKagG8K+mVMPwRwFAzy4vPTFJP4FZgJLAJeEXSl8zsZklfAK4zs+nxcczsI0mlkkaY2Syis4hHQu8rzKxAUitgmqR/mdlGokbnppjZj8J845P8nzBONvC6pOFmNjv022JmwyRdStSS7dhy6+su4JtmtljSaODvRG1V3QicbmarJXWsdq27jOdnDq7BsKh12QeA79ZgtGlmttbM9hA1F1D24/4RUUIo87iZlZrZYqIkcjBRezSXSvqQqNnzLkTt8ABMLZ8YgiOBtyxqHK4YeIjoTKA6jxC195MDfImo2QeA74azg8lEDamVzb+EqHHFilwoaSbwAXAo0ctt4vMp+39UfCRFLfkeDTwRlvkfRO3/A7wLTJQ0nujlWK6J8zMH19D8CZgJ3BcrKyYcyIT6+uaxfntin0tj3aV8fv8u306MEbVb8x0z+1xDdJJOJGoiuy49SpS43gZmm9m6MJ9TiF5Es1PSW0TtBQHsNrOS8hMJDcldBxxpZpskTYyNA59fzvLLnEX0boTDyk/XzL4ZziTOBmZIGhnOYFwT5WcOrkExswKi10JeGSteTlSNA/BFoFktJn2BpKxwHWIAUYNsLwPXKGoCHUmDFb1QpypTgRMkdQ3VOuOIfvCrZGZLid5U9ls+O7rvAGwKieFgolc7Vqc9UeLaIqk7cGa5/l+J/X+/XAxbgTxJF8Cn7yceET4PNLMpZnYj0UuG4s1BuybIzxxcQ/RH4NpY993A06H65SVqd1T/MdEPe3uiOvfdkiYQVT3NVFSpn09U5VMpM1sr6SdEzUgLeN7MkjaJ/AhRcih7B8dLwDclzSdKVpOrm4CZzZL0AVHLpSuJqoPiOkmaTXQGNa6CSVwM3CHpZ0RJ9lGi9y3/XtKgsEyvhzLXhHmrrM455/bi1UrOOef24snBOefcXjw5OOec24snB+ecc3vx5OCcc24vnhycc87txZODc865vfx/Kyniel9PCDYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "1.  The plot between Taken Taken for Gradient Descent v/s Number of Variables increases non-linearly\n",
        "2. The breaking point observed in this case was for Number of Variables = 100000\n",
        "\n",
        "# Potential Reason :    \n",
        "As the number of variables increase, performing gradient descent increases non-linearly.\n",
        "The RAM of the virtual machine Google colab had assigned me crashes when the number of columns = number of rows = 100000"
      ],
      "metadata": {
        "id": "EqIesZbMDFm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13 (k) : Training and validation NRMSE and number of nearly zero weights obtained using gradient descent with lambda2"
      ],
      "metadata": {
        "id": "Orz9DPti4QEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are looking for how L2 normalization shrink the weights. Does it make them zero? For what value of lambda? Keep w, noise_var etc. fixed.\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "def count_zeros(weights, threshold):\n",
        "  count = 0\n",
        "  for i in range(np.shape(weights)[1]):\n",
        "    if abs(weights[0][i]) < threshold:\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "FeatureDimension = 10\n",
        "NumberOfSamples = 1000\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "eta = 0.01\n",
        "epsilon = 0.001\n",
        "max_iter = 1000\n",
        "\n",
        "threshold = 0.05\n",
        "\n",
        "x = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "w = np.random.randn(1, FeatureDimension)\n",
        "\n",
        "# Splitting the dataset into training data and validation data using 80-20 split\n",
        "training_data, validation_data = x[:800,], x[-200:,]\n",
        "t, v = generateTargetVector(training_data, w, bias, noise_variance), generateTargetVector(validation_data, w, bias, noise_variance)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 0.1)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 1)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 2)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 3)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 4)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 5)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 6)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 7)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 8)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0, 9)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data, w_t1), v)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data, w_t2), v)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data, w_t3), v)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data, w_t4), v)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data, w_t5), v)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data, w_t6), v)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data, w_t7), v)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data, w_t8), v)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data, w_t9), v)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data, w_t10), v)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)\n",
        "\n",
        "print(\"Printing the number of nearly zero weights obtained using gradient descent by varying the value of lambda2 with a threshold of {}\".format(threshold))\n",
        "print(\"With lambda2 = 0.1 : \", count_zeros(w_t1, threshold))\n",
        "print(\"With lambda2 = 1 : \", count_zeros(w_t2, threshold))\n",
        "print(\"With lambda2 = 2 : \", count_zeros(w_t3, threshold))\n",
        "print(\"With lambda2 = 3 : \", count_zeros(w_t4, threshold))\n",
        "print(\"With lambda2 = 4 : \", count_zeros(w_t5, threshold))\n",
        "print(\"With lambda2 = 5 : \", count_zeros(w_t6, threshold))\n",
        "print(\"With lambda2 = 6 : \", count_zeros(w_t7, threshold))\n",
        "print(\"With lambda2 = 7 : \", count_zeros(w_t8, threshold))\n",
        "print(\"With lambda2 = 8 : \", count_zeros(w_t9, threshold))\n",
        "print(\"With lambda2 = 9 : \", count_zeros(w_t10, threshold))\n",
        "if np.argmin(nrmse_v) == 0:\n",
        "  optimal_lambda2 = 0.1\n",
        "else:\n",
        "  optimal_lambda2 = np.argmin(nrmse_v)\n",
        "print(\"Minimum NRMSE was obtained using lambda2 = {}\".format(optimal_lambda2))"
      ],
      "metadata": {
        "id": "jRSbvNM84Vow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "02da8f10-dbb0-4ff5-8dba-6651a4ec5b2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the number of nearly zero weights obtained using gradient descent by varying the value of lambda2 with a threshold of 0.05\n",
            "With lambda2 = 0.1 :  0\n",
            "With lambda2 = 1 :  0\n",
            "With lambda2 = 2 :  0\n",
            "With lambda2 = 3 :  0\n",
            "With lambda2 = 4 :  2\n",
            "With lambda2 = 5 :  2\n",
            "With lambda2 = 6 :  2\n",
            "With lambda2 = 7 :  3\n",
            "With lambda2 = 8 :  3\n",
            "With lambda2 = 9 :  3\n",
            "Minimum NRMSE was obtained using lambda2 = 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMLElEQVR4nO3dYWjc933H8c/Hp6SVk2WllyOUS113KKSUwZZwBEZLYZk91GxsT/aghU3aKPhJJ2thMLo92x7k4ZgsRsG0XSXWtZRuhVEybQ5rKYUu3dnJ5iRO6RGc1KKtL1e22rUXT9J3D05ybFeO/srur9/XuvcLTCzruHxIxJuf7/5354gQACCvA6UHAADeGqEGgOQINQAkR6gBIDlCDQDJTdRxp/fff38cPny4jrsGgH3p9OnTr0dEa7vv1RLqw4cPq9vt1nHXALAv2X71dt/joQ8ASI5QA0ByhBoAkiPUAJAcoQaA5Ag1ACRHqAEguVquowZQn8XFRfV6vdIztLq6Kklqt9tFd0xNTWlubq7ohroRagBvy9WrV0tPGBuEGrjDZDk9zs/PS5IWFhYKL9n/eIwaAJIj1ACQHKEGgOQINQAkx5OJwC5kuTQug63/DltPKo67Oi8TJNTALvR6PX3vxed06N710lOKu/t/h38hf+NV3nv+tcuNWu+fUAO7dOjedf3Zoz8pPQOJPHXmvlrvn8eoASA5Qg0AyVUKte132f6K7Zdtn7P9K3UPAwAMVX2MekHSSkT8ju27JR2scRMA4AY7htr2z0v6iKTfl6SIuCbpWr2zAABbqjz08X5JfUl/Y/s525+xfc+tN7J9zHbXdrff7498KACMqyqhnpD0qKRPR8Qjkn4q6VO33igiTkZEJyI6rVZrxDMBYHxVCfUFSRci4tnNr7+iYbgBAHtgx1BHxA8lfd/2w5t/9GuSXqp1FQDguqpXfcxJ+sLmFR+vSPqD+iYBAG5UKdQR8bykTs1bAADb4JWJAJAcb8oE7MLq6qp+eqlR+5vw4M7y6qWG7tn8VPY6cKIGgOQ4UQO70G639cbaD3ibU9zkqTP36R3tdm33z4kaAJIj1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJAcoQaA5Ag1ACRHqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkByhBoDkCDUAJFfpw21tn5d0SdK6pLWI6NQ5CgDwpt18CvmvRsTrtS0BAGyLhz4AILmqoQ5J/2L7tO1j293A9jHbXdvdfr8/uoUAMOaqhvrDEfGopI9K+qTtj9x6g4g4GRGdiOi0Wq2RjgSAcVYp1BGxuvnPi5K+KumxOkcBAN6045OJtu+RdCAiLm3+/tcl/UXty4CkXrvc0FNn7is9o7gfXRme8x44uFF4SXmvXW7ooRrvv8pVHw9I+qrtrdv/XUSs1LgJSGtqaqr0hDSu9XqSpHe8j/8mD6nen40dQx0Rr0j6pdoWAHeQubm50hPSmJ+flyQtLCwUXrL/cXkeACRHqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJBc5VDbbth+zvbX6hwEALjZbk7U85LO1TUEALC9SqG2/aCk35D0mXrnAABuVfVE/VeS/kTSxu1uYPuY7a7tbr/fH8k4AECFUNv+TUkXI+L0W90uIk5GRCciOq1Wa2QDAWDcVTlRf0jSb9k+L+lLkh63/be1rgIAXLdjqCPiTyPiwYg4LOljkv41In639mUAAElcRw0A6U3s5sYR8Q1J36hlCQBgW5yoASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQ3K4uzwNQ3uLionq9XukZ1zfMz88X3TE1NaW5ubmiG+pGqAG8LZOTk6UnjA1CDdxh9vvpET+Lx6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJAcoQaA5Ag1ACRHqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkNyOobb9Ttvfsf0ftl+0/ed7MQwAMFTl/ajfkPR4RFy2fZekb9n+p4j4t5q3AQBUIdQREZIub3551+avqHMUAOBNlR6jtt2w/byki5JORcSz9c4CAGypFOqIWI+IX5b0oKTHbP/irbexfcx213a33++PeicAjK1dXfUREf8l6euSprf53smI6EREp9VqjWofAIy9Kld9tGy/a/P3k5KOSnq57mEAgKEqV328R9KS7YaGYf9yRHyt3lkAgC1Vrvr4T0mP7MEWAMA2eGUiACRHqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJAcoQaA5HYMte332v667Zdsv2h7fi+GAQCGJircZk3SH0fEGds/J+m07VMR8VLN2wAAqnCijogfRMSZzd9fknROUrvuYQCAoV09Rm37sKRHJD27zfeO2e7a7vb7/dGsAwBUD7XteyX9vaQ/ioif3Pr9iDgZEZ2I6LRarVFuBICxVinUtu/SMNJfiIh/qHcSAOBGVa76sKTPSjoXEX9Z/yQAwI2qnKg/JOn3JD1u+/nNX0/UvAsAsGnHy/Mi4luSvAdbAADb4JWJAJAcoQaA5Ag1ACRX5SXkY2lxcVG9Xq/ohtXVVUlSu13+haBTU1Oam5srPQMYS4Q6satXr5aeACCBdKHOcJLFz+r1epqfL/vGiZzqMa7ShbrX6+n5F85p/eC7S08p7sC1kCSdfuVHhZeU17jy49ITgGLShVqS1g++W1c/wGtq8KbJl58uPQEohqs+ACC5dCfq1dVVNa78Nyco3KRxZaDV1bXSM4AiOFEDQHLpTtTtdls/fGOCx6hxk8mXn1a7/UDpGUARnKgBIDlCDQDJEWoAb8tgMNDx48c1GAxKT9n3CDWAt2VpaUlnz57V8vJy6Sn7XronE6Xhq9C4PE868D/DzxDeeOd9hZeUN3xlIk8mZjEYDLSysqKI0MrKimZmZtRsNkvP2rfShXpqaqr0hDR6vUuSpKlfIFDSA/xsJLK0tKSNjQ1J0vr6upaXl/Xkk08WXrV/OSJGfqedTie63e7I73fcbL0J0sLCQuElwM2eeOIJXbly5frXBw8e1NNP87fg/w/bpyOis933eIwawK4dOXJEExPDv5BPTEzo6NGjhRftb4QawK7Nzs7qwIFhPhqNhmZmZgov2t8INYBdazabmp6elm1NT0/zRGLN0j2ZCODOMDs7q/Pnz3Oa3gM7nqhtf872Rdsv7MUgAHeGZrOpEydOcJreA1Ue+vi8pOmadwAAbmPHUEfENyXxOUgAUAhPJgJAciN7MtH2MUnHJOnQoUOjuttiMnwa+ta/v/Snf0t8AjhQ0shO1BFxMiI6EdFptVqjutuxNjk5qcnJydIzABTG5Xm3wekRQBZVLs/7oqRvS3rY9gXbn6h/FgBgy44n6oj4+F4MAQBsj6s+ACA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhDqxwWCg48ePazAYlJ4CoCBCndjS0pLOnj2r5eXl0lMAFESokxoMBlpZWVFEaGVlhVM1MMYIdVJLS0va2NiQJK2vr3OqBsYYoU7qmWee0dramiRpbW1Np06dKrwIQCmEOqkjR45oYmL4ATwTExM6evRo4UUASiHUSc3OzurAgeH/nkajoZmZmcKLAJRCqJNqNpuanp6WbU1PT6vZbJaeBKCQHT/cFuXMzs7q/PnznKaBMUeoE2s2mzpx4kTpGQAK46EPAEiOUANAcoQaAJIj1ACQnCNi9Hdq9yW9OvI7Hk/3S3q99AjgNvj5HJ33RURru2/UEmqMju1uRHRK7wC2w8/n3uChDwBIjlADQHKEOr+TpQcAb4Gfzz3AY9QAkBwnagBIjlADQHKEOjHb07a/a7tn+1Ol9wBbbH/O9kXbL5TeMg4IdVK2G5L+WtJHJX1Q0sdtf7DsKuC6z0uaLj1iXBDqvB6T1IuIVyLimqQvSfrtwpsASVJEfFPSj0vvGBeEOq+2pO/f8PWFzT8DMGYINQAkR6jzWpX03hu+fnDzzwCMGUKd179Lesj2+23fLeljkv6x8CYABRDqpCJiTdIfSvpnSeckfTkiXiy7Chiy/UVJ35b0sO0Ltj9RetN+xkvIASA5TtQAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcv8H1SWzAiF8HWAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "1.  Mean of Training_NRMSE < Mean of Validation_NRMSE\n",
        "2. Spread of Training_NRMSE < Spread of Validation_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "The introduction of the regularization term makes sure that our model is not overfitting to the training data. This allows it to generalize better on unseen data. In this way, the L2 regularization deals with independent variables that are highly correlated by constricting the coefficient and keeping all the variables.\n",
        "\n",
        "\n",
        "When value of lambda2 is too high, the model will be simple, and can underfit the data. The model won't learn enough about the training data to make useful predictions.\n",
        "\n",
        "When the value of lambda2 is too low, the model will be more complex, and can overfit the data. The model will learn too much about the particularities of the training data, and won't be able to generalize to new data.\n",
        "\n",
        "L2 regularization tries to estimate the mean of the data to avoid overfitting."
      ],
      "metadata": {
        "id": "g5TiFd10DeZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13 (l) : Training and validation NRMSE and number of nearly zero weights obtained using gradient descent with lambda1"
      ],
      "metadata": {
        "id": "Z9TCvHOe4YQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are looking for how L1 normalization shrink the weights. Does it make them zero? For what value of lambda? Keep w, noise_var etc. fixed.\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "def count_zeros(weights, threshold):\n",
        "  count = 0\n",
        "  for i in range(np.shape(weights)[1]):\n",
        "    if abs(weights[0][i]) < threshold:\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "FeatureDimension = 10\n",
        "NumberOfSamples = 1000\n",
        "bias = 1\n",
        "noise_variance = 0.25\n",
        "eta = 0.01\n",
        "epsilon = 0.001\n",
        "max_iter = 1000\n",
        "\n",
        "threshold = 0.05\n",
        "\n",
        "x = generateDataMatrix(NumberOfSamples, FeatureDimension)\n",
        "w = np.random.randn(1, FeatureDimension)\n",
        "\n",
        "# Splitting the dataset into training data and validation data using 80-20 split\n",
        "training_data, validation_data = x[:800,], x[-200:,]\n",
        "t, v = generateTargetVector(training_data, w, bias, noise_variance), generateTargetVector(validation_data, w, bias, noise_variance)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 0.1, 0)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 1, 0)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 2, 0)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 3, 0)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 4, 0)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 5, 0)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 6, 0)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 7, 0)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 8, 0)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data, t, eta, max_iter, epsilon, 9, 0)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data, w_t1), v)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data, w_t2), v)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data, w_t3), v)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data, w_t4), v)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data, w_t5), v)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data, w_t6), v)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data, w_t7), v)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data, w_t8), v)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data, w_t9), v)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data, w_t10), v)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "\n",
        "mse_v = np.array([mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6, mse_v7, mse_v8, mse_v9, mse_v10])\n",
        "nrmse_v = nrmse(mse_v, noise_variance)\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)\n",
        "\n",
        "print(\"Printing the number of nearly zero weights obtained using gradient descent by varying the value of lambda1 with a threshold of {}\".format(threshold))\n",
        "print(\"With lambda1 = 0.1 : \", count_zeros(w_t1, threshold))\n",
        "print(\"With lambda1 = 1 : \", count_zeros(w_t2, threshold))\n",
        "print(\"With lambda1 = 2 : \", count_zeros(w_t3, threshold))\n",
        "print(\"With lambda1 = 3 : \", count_zeros(w_t4, threshold))\n",
        "print(\"With lambda1 = 4 : \", count_zeros(w_t5, threshold))\n",
        "print(\"With lambda1 = 5 : \", count_zeros(w_t6, threshold))\n",
        "print(\"With lambda1 = 6 : \", count_zeros(w_t7, threshold))\n",
        "print(\"With lambda1 = 7 : \", count_zeros(w_t8, threshold))\n",
        "print(\"With lambda1 = 8 : \", count_zeros(w_t9, threshold))\n",
        "print(\"With lambda1 = 9 : \", count_zeros(w_t10, threshold))\n",
        "if np.argmin(nrmse_v) == 0:\n",
        "  optimal_lambda1 = 0.1\n",
        "else:\n",
        "  optimal_lambda1 = np.argmin(nrmse_v)\n",
        "print(\"Minimum NRMSE was obtained using lambda1 = {}\".format(optimal_lambda1))"
      ],
      "metadata": {
        "id": "mM20tEU54eH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "e7065ee7-1488-4332-a864-ce806698d26b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29213748 0.83391211 1.50017388 1.83112221 1.925352   1.96911333\n",
            " 1.9461472  1.95738699 1.94690203 1.95582941]\n",
            "-----\n",
            "[1.14848539 3.38908743 6.18740507 7.67885617 7.98051272 8.21148065\n",
            " 8.11403099 8.19813759 8.11005056 8.18530208]\n",
            "Printing the number of nearly zero weights obtained using gradient descent by varying the value of lambda1 with a threshold of 0.05\n",
            "With lambda1 = 0.1 :  1\n",
            "With lambda1 = 1 :  2\n",
            "With lambda1 = 2 :  5\n",
            "With lambda1 = 3 :  7\n",
            "With lambda1 = 4 :  8\n",
            "With lambda1 = 5 :  8\n",
            "With lambda1 = 6 :  6\n",
            "With lambda1 = 7 :  6\n",
            "With lambda1 = 8 :  4\n",
            "With lambda1 = 9 :  7\n",
            "Minimum NRMSE was obtained using lambda1 = 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "1.  Mean of Training_NRMSE < Mean of Validation_NRMSE\n",
        "2. Spread of Training_NRMSE < Spread of Validation_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "The introduction of the regularization term makes sure that our model is not overfitting to the training data. This allows it to generalize better on unseen data. In this way, the L1 regularization deals with independent variables that are highly correlated by constricting the coefficient and keeping all the variables.\n",
        "\n",
        "\n",
        "When value of lambda2 is too high, the model will be simple, and can underfit the data. The model won't learn enough about the training data to make useful predictions.\n",
        "\n",
        "When the value of lambda2 is too low, the model will be more complex, and can overfit the data. The model will learn too much about the particularities of the training data, and won't be able to generalize to new data.\n",
        "\n",
        "L1 regularization tries to estimate the median of the data to avoid overfitting."
      ],
      "metadata": {
        "id": "pAA0qLb3EN4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13 (m) : Training and validation NRMSE for optimal lambda2 with noise variance"
      ],
      "metadata": {
        "id": "GhJumsxG4eVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vary noise variance and keep lambda2 to be optimal\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension) # w is kept fixed\n",
        "eta = 0.01 # eta is kept fixed\n",
        "bias = 1 # bias is kept fixed\n",
        "max_iter = 1000 # max_iter is kept fixed\n",
        "epsilon = 0.001 # min_change_nrmse is kept fixed\n",
        "noise_variance = 1\n",
        "\n",
        "optimal_lambda2 = 0.1\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, weights, bias, 0.1)\n",
        "v1 = generateTargetVector(validation_data1, weights, bias, 0.1)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, weights, bias, 1)\n",
        "v2 = generateTargetVector(validation_data2, weights, bias, 1)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, weights, bias, 2)\n",
        "v3 = generateTargetVector(validation_data3, weights, bias, 2)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, weights, bias, 3)\n",
        "v4 = generateTargetVector(validation_data4, weights, bias,3)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, weights, bias, 4)\n",
        "v5 = generateTargetVector(validation_data5, weights, bias, 4)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, weights, bias, 5)\n",
        "v6 = generateTargetVector(validation_data6, weights, bias, 5)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, weights, bias, 6)\n",
        "v7 = generateTargetVector(validation_data7, weights, bias, 6)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, weights, bias, 7)\n",
        "v8 = generateTargetVector(validation_data8, weights, bias, 7)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, weights, bias, 8)\n",
        "v9 = generateTargetVector(validation_data9, weights, bias, 8)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, weights, bias, 9)\n",
        "v10 = generateTargetVector(validation_data10, weights, bias, 9)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data1, t1, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data2, t2, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data3, t3, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data4, t4, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data5, t5, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data6, t6, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data7, t7, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data8, t8, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data9, t9, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data10, t10, eta, max_iter, epsilon, 0, optimal_lambda2)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "nrmse_v1 = nrmse(mse_v1, 0.1)\n",
        "nrmse_v2 = nrmse(mse_v2, 1)\n",
        "nrmse_v3 = nrmse(mse_v3, 2)\n",
        "nrmse_v4 = nrmse(mse_v4, 3)\n",
        "nrmse_v5 = nrmse(mse_v5, 4)\n",
        "nrmse_v6 = nrmse(mse_v6, 5)\n",
        "nrmse_v7 = nrmse(mse_v7, 6)\n",
        "nrmse_v8 = nrmse(mse_v8, 7)\n",
        "nrmse_v9 = nrmse(mse_v9, 8)\n",
        "nrmse_v10 = nrmse(mse_v10,9)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "nrmse_v = np.array([nrmse_v1, nrmse_v2, nrmse_v3, nrmse_v4, nrmse_v5, nrmse_v6, nrmse_v7, nrmse_v8, nrmse_v9, nrmse_v10])\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "id": "kQYiMX1q4m9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7de8c38e-ed6b-4986-c9d8-a828404a51a2"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc849174970>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   Spread of Validation_NRMSE <  Spread of Training_NRMSE\n",
        "2.   Mean of Validation_NRMSE < Mean of Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "\n",
        "The increase in Training_NRMSE can be because of the variance of the noise present in the target vector due to which it is becoming difficult for the model to fit over training data."
      ],
      "metadata": {
        "id": "D3pCbbPnEqQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13 (n) : Training and validation NRMSE for optimal lambda1 with noise variance"
      ],
      "metadata": {
        "id": "RwCWnu4x4gQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vary noise variance and keep lambda1 to be optimal\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "NumberOfSamples = 1000\n",
        "featureDimension = 10\n",
        "weights = np.random.rand(1, featureDimension) # w is kept fixed\n",
        "eta = 0.01 # eta is kept fixed\n",
        "bias = 1 # bias is kept fixed\n",
        "max_iter = 1000 # max_iter is kept fixed\n",
        "epsilon = 0.001 # min_change_nrmse is kept fixed\n",
        "noise_variance = 1\n",
        "\n",
        "optimal_lambda1 = 0.1\n",
        "\n",
        "def nrmse(mse, noise_variance):\n",
        "  return np.sqrt(mse) / np.sqrt(noise_variance)\n",
        "\n",
        "# Generating training datasets with different number of training samples\n",
        "random.seed(11)\n",
        "x1 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(12)\n",
        "x2 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(13)\n",
        "x3 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(14)\n",
        "x4 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(15)\n",
        "x5 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(16)\n",
        "x6 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(17)\n",
        "x7 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(18)\n",
        "x8 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(19)\n",
        "x9 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "random.seed(20)\n",
        "x10 = generateDataMatrix(NumberOfSamples, featureDimension)\n",
        "\n",
        "# Now I have generated 10 training datasets. Now I would be splitting each training dataset into a training and validation dataset on a 80-20 split-ratio.\n",
        "training_data1, validation_data1 = x1[:800,], x1[-200:,]\n",
        "t1 = generateTargetVector(training_data1, weights, bias, 0.1)\n",
        "v1 = generateTargetVector(validation_data1, weights, bias, 0.1)\n",
        "\n",
        "training_data2, validation_data2 = x2[:800,], x2[-200:,]\n",
        "t2 = generateTargetVector(training_data2, weights, bias, 1)\n",
        "v2 = generateTargetVector(validation_data2, weights, bias, 1)\n",
        "\n",
        "training_data3, validation_data3 = x3[:800,], x3[-200:,]\n",
        "t3 = generateTargetVector(training_data3, weights, bias, 2)\n",
        "v3 = generateTargetVector(validation_data3, weights, bias, 2)\n",
        "\n",
        "training_data4, validation_data4 = x4[:800,], x4[-200:,]\n",
        "t4 = generateTargetVector(training_data4, weights, bias, 3)\n",
        "v4 = generateTargetVector(validation_data4, weights, bias,3)\n",
        "\n",
        "training_data5, validation_data5 = x5[:800,], x5[-200:,]\n",
        "t5 = generateTargetVector(training_data5, weights, bias, 4)\n",
        "v5 = generateTargetVector(validation_data5, weights, bias, 4)\n",
        "\n",
        "training_data6, validation_data6 = x6[:800,], x6[-200:,]\n",
        "t6 = generateTargetVector(training_data6, weights, bias, 5)\n",
        "v6 = generateTargetVector(validation_data6, weights, bias, 5)\n",
        "\n",
        "training_data7, validation_data7 = x7[:800,], x7[-200:,]\n",
        "t7 = generateTargetVector(training_data7, weights, bias, 6)\n",
        "v7 = generateTargetVector(validation_data7, weights, bias, 6)\n",
        "\n",
        "training_data8, validation_data8 = x8[:800,], x8[-200:,]\n",
        "t8 = generateTargetVector(training_data8, weights, bias, 7)\n",
        "v8 = generateTargetVector(validation_data8, weights, bias, 7)\n",
        "\n",
        "training_data9, validation_data9 = x9[:800,], x9[-200:,]\n",
        "t9 = generateTargetVector(training_data9, weights, bias, 8)\n",
        "v9 = generateTargetVector(validation_data9, weights, bias, 8)\n",
        "\n",
        "training_data10, validation_data10 = x10[:800,], x10[-200:,]\n",
        "t10 = generateTargetVector(training_data10, weights, bias, 9)\n",
        "v10 = generateTargetVector(validation_data10, weights, bias, 9)\n",
        "\n",
        "w_t1, nrmse_t1 = estimateLRweights(training_data1, t1, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t2, nrmse_t2 = estimateLRweights(training_data2, t2, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t3, nrmse_t3 = estimateLRweights(training_data3, t3, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t4, nrmse_t4 = estimateLRweights(training_data4, t4, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t5, nrmse_t5 = estimateLRweights(training_data5, t5, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t6, nrmse_t6 = estimateLRweights(training_data6, t6, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t7, nrmse_t7 = estimateLRweights(training_data7, t7, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t8, nrmse_t8 = estimateLRweights(training_data8, t8, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t9, nrmse_t9 = estimateLRweights(training_data9, t9, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "w_t10, nrmse_t10 = estimateLRweights(training_data10, t10, eta, max_iter, epsilon, optimal_lambda1, 0)\n",
        "\n",
        "mse_v1 = computeMSE(computeLRestimate(validation_data1, w_t1), v1)\n",
        "mse_v2 = computeMSE(computeLRestimate(validation_data2, w_t2), v2)\n",
        "mse_v3 = computeMSE(computeLRestimate(validation_data3, w_t3), v3)\n",
        "mse_v4 = computeMSE(computeLRestimate(validation_data4, w_t4), v4)\n",
        "mse_v5 = computeMSE(computeLRestimate(validation_data5, w_t5), v5)\n",
        "mse_v6 = computeMSE(computeLRestimate(validation_data6, w_t6), v6)\n",
        "mse_v7 = computeMSE(computeLRestimate(validation_data7, w_t7), v7)\n",
        "mse_v8 = computeMSE(computeLRestimate(validation_data8, w_t8), v8)\n",
        "mse_v9 = computeMSE(computeLRestimate(validation_data9, w_t9), v9)\n",
        "mse_v10 = computeMSE(computeLRestimate(validation_data10, w_t10), v10)\n",
        "\n",
        "nrmse_v1 = nrmse(mse_v1, 0.1)\n",
        "nrmse_v2 = nrmse(mse_v2, 1)\n",
        "nrmse_v3 = nrmse(mse_v3, 2)\n",
        "nrmse_v4 = nrmse(mse_v4, 3)\n",
        "nrmse_v5 = nrmse(mse_v5, 4)\n",
        "nrmse_v6 = nrmse(mse_v6, 5)\n",
        "nrmse_v7 = nrmse(mse_v7, 6)\n",
        "nrmse_v8 = nrmse(mse_v8, 7)\n",
        "nrmse_v9 = nrmse(mse_v9, 8)\n",
        "nrmse_v10 = nrmse(mse_v10,9)\n",
        "\n",
        "nrmse_t = np.array([nrmse_t1, nrmse_t2, nrmse_t3, nrmse_t4, nrmse_t5, nrmse_t6, nrmse_t7, nrmse_t8, nrmse_t9, nrmse_t10])\n",
        "nrmse_v = np.array([nrmse_v1, nrmse_v2, nrmse_v3, nrmse_v4, nrmse_v5, nrmse_v6, nrmse_v7, nrmse_v8, nrmse_v9, nrmse_v10])\n",
        "\n",
        "plot_arr = [nrmse_t, nrmse_v]\n",
        "sns.boxplot(data=plot_arr)"
      ],
      "metadata": {
        "id": "y4UddmfT4nXw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8d58541d-ee7a-47b0-ffe4-d0267dfc3baf"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc849291370>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations : \n",
        "\n",
        "1.   Spread of Validation_NRMSE <  Spread of Training_NRMSE\n",
        "2.   Mean of Validation_NRMSE < Mean of Training_NRMSE\n",
        "\n",
        "# Potential Reason :    \n",
        "\n",
        "The increase in Training_NRMSE can be because of the variance of the noise present in the target vector due to which it is becoming difficult for the model to fit over training data."
      ],
      "metadata": {
        "id": "W93wNS5QFD-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My overall learning points by doing the entire assignment : \n",
        "\n",
        "1.   Since a large amount of time was given to us for completing the assignment, I was able to learn to code on my own at my own pace. \n",
        "2.   I also got a practical feel of the impact some of the model parameters had on the overall model as I varied the model parameter (like learning rate) and kept everything else same.\n",
        "3. Since I was able to build a linear regression model completely from scratch using popular libraries like NumPy, I feel more confident on my coding skills. I was learning from making mistakes and debugging them on my own with little help from the internet allowed me to learn much more than I would have if I had taken help from my peers.\n",
        "4. As I learnt the fundamentals of machine learning, this would certainly allow me to use these techniques to build real world AI applications.\n",
        "5. Throughout the assignment, I was constantly revising the key concepts taught in class and simultaneously gained the practical know-how. \n",
        "6. Certain questions really boggled my mind like the different parts within Task 13 for which I had to think outside the box. They surely tested my problem solving skills.\n",
        "7. The practise of writing copious comments after every line of code also helped me immensely when I sat down after a couple of days or when I was trying to debug a specific part of the code. Furthermore, the practise of having a trailing code block after each and every function, helped me to cross-check if the function is doing exactly what I want it to do.\n",
        "8. Through this assignment, I was able to develop a deeper understanding of the linear regression model and it's limitations. Along with these, I also gained familiarity with a wide range of techniques and methods like estimating the weights of linear regression using pinv.\n",
        "9. In a broad sense, I comprehended where I need to go in order to learn more about the techniqes taught in class and those that were not covered in the class \n",
        "\n"
      ],
      "metadata": {
        "id": "QBTiscis4ukw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References \n",
        "\n",
        "1.   For Python related syntax queries : [GeeksForGeeks](https://www.geeksforgeeks.org/)\n",
        "2.   For Python related debugging queries : [StackOverflow](https://stackoverflow.com/)\n",
        "3. To get a better understanding of the problem statement : Linear Regression Slides provided by Prof. Amit Sethi, IIT Bombay\n",
        "4. Bishop - Pattern Recognition And Machine Learning - Springer - 2006 Edition\n",
        "5. Understanding Regularization in Machine Learning [Regularization](https://towardsdatascience.com/understanding-regularization-in-machine-learning-d7dd0729dde5#:~:text=L2%20Regularization%20or%20Ridge%20regression,-The%20cost%20function&text=The%20value%20of%20lambda%20can%20vary%20from%200%20to%20infinity.)\n",
        "6. To understand and implement the functionalities provided by the Numpy library - [Numpy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html)\n",
        "7. The usage of np.std(t) instead of np.sqrt(noise_variance) in Task 12 was motivated/inspired by **200070053**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rwVG0ET540o_"
      }
    }
  ]
}